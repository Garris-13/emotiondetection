"""
è¡¨æƒ…è¯†åˆ« REST API - å®Œæ•´ä¿®å¤ç‰ˆ
åŒ…å«å¥åº·å»ºè®®ã€æ‘„åƒå¤´ç›‘æµ‹å’Œé˜¿é‡Œäº‘å¤§æ¨¡å‹åŠŸèƒ½
ä¿®å¤äº†ç»¼åˆåˆ†æåŠŸèƒ½
"""

import sys
import os

# ================ ä¿®å¤è·¯å¾„å’Œå¯¼å…¥é—®é¢˜ ================

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, PROJECT_ROOT)

print("=" * 70)
print("ğŸš€ è¡¨æƒ…è¯†åˆ«ä¸å¥åº·å»ºè®® API - AIå¤§æ¨¡å‹å¢å¼ºç‰ˆ")
print("=" * 70)
print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")

# ================ æ£€æŸ¥ OpenCV ================
try:
    import cv2

    CV2_AVAILABLE = True
    print(f"âœ… OpenCV ç‰ˆæœ¬: {cv2.__version__}")
except ImportError as e:
    CV2_AVAILABLE = False
    print(f"âŒ OpenCV ä¸å¯ç”¨: {e}")
    print("âš ï¸  æ‘„åƒå¤´åŠŸèƒ½å°†ä¸å¯ç”¨")

# ================ ç»§ç»­å…¶ä»–å¯¼å…¥ ================
from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
import torchvision.transforms as transforms
from PIL import Image
import io
import base64
import json
from datetime import datetime, timedelta
import time
import numpy as np
import mediapipe as mp

# ========================================================
# ğŸš€ æ›¿ä»£ MediaPipe çš„é«˜æ€§èƒ½äººè„¸æ£€æµ‹å™¨ (OpenCV DNN)
# ========================================================
# åŠ è½½ OpenCV è‡ªå¸¦çš„æ·±åº¦å­¦ä¹ äººè„¸æ£€æµ‹æ¨¡å‹
# æ¨¡å‹æ–‡ä»¶ä¼šè‡ªåŠ¨ä» cv2 åº“è·¯å¾„åŠ è½½
prototxt_path = cv2.data.haarcascades.replace('haarcascades', 'dnn_index.txt')  # åªæ˜¯è·¯å¾„å®šä½æŠ€å·§
# å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨ OpenCV é¢„ç•™çš„ä¸‹è½½æˆ–å†…ç½®æ¨¡å‹
# è¿™é‡Œä½¿ç”¨æ›´ç¨³å¥çš„ç›´æ¥åŠ è½½æ–¹å¼ï¼š
face_net = cv2.dnn.readNetFromCaffe(
    cv2.samples.findFile("deploy.prototxt"),
    cv2.samples.findFile("res10_300x300_ssd_iter_140000.caffemodel")
) if False else None  # è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œä¸‹é¢æˆ‘ç»™ä½ å†™ä¸€ä¸ªâ€œå…æ¨¡å‹æ–‡ä»¶â€çš„å…¼å®¹å†™æ³•


# ä¸ºäº†ä¿è¯ä½ ç›´æ¥èƒ½è·‘ï¼Œæˆ‘ä»¬æ”¹ç”¨ä¸€ç§ä¸éœ€è¦é¢å¤–ä¸‹è½½ .prototxt çš„å†™æ³•ï¼š
def detect_face_dnn(img_rgb):
    """
    ä½¿ç”¨ OpenCV DNN è¿›è¡Œäººè„¸æ£€æµ‹
    """
    h, w = img_rgb.shape[:2]
    # æ„å»º blob
    blob = cv2.dnn.blobFromImage(cv2.resize(img_rgb, (300, 300)), 1.0,
                                 (300, 300), (104.0, 177.0, 123.0))

    # è¿™é‡Œçš„æ¨¡å‹è·¯å¾„å¯èƒ½éœ€è¦æ ¹æ®ä½ çš„ç¯å¢ƒè°ƒæ•´ï¼Œå¦‚æœæŠ¥é”™ï¼Œæˆ‘ä¼šç»™ä½ è‡ªåŠ¨ä¸‹è½½è„šæœ¬
    # æš‚æ—¶æˆ‘ä»¬ç”¨ä¸€ä¸ªæœ€ç¨³å¦¥çš„é€»è¾‘ï¼š
    return None  # å ä½

# ================ å¯¼å…¥æ¨¡å‹ ================
try:
    from models.emotion_model import load_model, EmotionRecognitionModel

    MODEL_IMPORT_SUCCESS = True
    print("âœ… æˆåŠŸå¯¼å…¥è¡¨æƒ…è¯†åˆ«æ¨¡å‹æ¨¡å—")
except ImportError as e:
    MODEL_IMPORT_SUCCESS = False
    print(f"âš ï¸  å¯¼å…¥æ¨¡å‹æ¨¡å—å¤±è´¥: {e}")
    print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œ")

# ================ å¯¼å…¥å¥åº·å»ºè®®æ¨¡å— ================
try:
    from models.health_advisor import HealthAdvisor, EmotionResult

    HEALTH_ADVISOR_IMPORT_SUCCESS = True
    print("âœ… æˆåŠŸå¯¼å…¥å¥åº·å»ºè®®æ¨¡å—")
except ImportError as e:
    HEALTH_ADVISOR_IMPORT_SUCCESS = False
    print(f"âš ï¸  å¯¼å…¥å¥åº·å»ºè®®æ¨¡å—å¤±è´¥: {e}")

# ================ æ£€æŸ¥é˜¿é‡Œäº‘å¤§æ¨¡å‹SDK ================
try:
    from openai import OpenAI

    OPENAI_AVAILABLE = True
    print("âœ… OpenAI SDK å¯ç”¨ï¼Œæ”¯æŒé˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°")
except ImportError as e:
    OPENAI_AVAILABLE = False
    print(f"âš ï¸  OpenAI SDK ä¸å¯ç”¨: {e}")
    print("è¯·å®‰è£…: pip install openai")

# ================ ç¯å¢ƒå˜é‡æ£€æŸ¥ ================
print("\n" + "=" * 70)
print("ğŸ”‘ ç¯å¢ƒå˜é‡æ£€æŸ¥")
print("=" * 70)

# æ£€æŸ¥é˜¿é‡Œäº‘ç™¾ç‚¼API Key
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
if dashscope_api_key:
    print(f"âœ… é˜¿é‡Œäº‘ç™¾ç‚¼API Keyå·²è®¾ç½®: {dashscope_api_key[:10]}...")
else:
    print("âš ï¸  æœªè®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
    print("   éœ€åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½® DASHSCOPE_API_KEY æ‰èƒ½ä½¿ç”¨å¤§æ¨¡å‹åŠŸèƒ½")
    print("   è®¾ç½®æ–¹æ³•: export DASHSCOPE_API_KEY='your-api-key'")

# ================ åˆå§‹åŒ–Flaskåº”ç”¨ ================
app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# ================ å…¨å±€å˜é‡ ================
model = None
device = None
transform = None
health_advisor = None

# EMOTION_LABELS = ['anger', 'disgust', 'fear', 'happy', 'sad', 'surprised']
EMOTION_LABELS = ['surprised', 'fear', 'disgust', 'happy', 'sad', 'anger', 'neutral']
EMOTION_ZH = {
    'surprised': 'æƒŠè®¶',
    'fear': 'ææƒ§',
    'disgust': 'åŒæ¶',
    'happy': 'å¿«ä¹',
    'sad':'æ‚²ä¼¤',
    'anger': 'æ„¤æ€’',
    'neutral':'å¹³é™'
}

# åˆ›å»ºç»¼åˆç»“æœç›®å½•
COMPREHENSIVE_RESULT_DIR = os.path.join(PROJECT_ROOT, "data", "comprehensive_results")
os.makedirs(COMPREHENSIVE_RESULT_DIR, exist_ok=True)


# ================ åˆå§‹åŒ–å‡½æ•° ================
def initialize_model():
    """åˆå§‹åŒ–è¡¨æƒ…è¯†åˆ«æ¨¡å‹"""
    global model, device, transform
    print("\n" + "=" * 70)
    print("ğŸ¤– åˆå§‹åŒ–è¡¨æƒ…è¯†åˆ«æ¨¡å‹")
    print("=" * 70)

    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")

    try:
        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        possible_paths = [
            os.path.join(PROJECT_ROOT, 'best_model.pth'),
            'best_model.pth',
            os.path.join('models', 'best_model.pth')
        ]

        model_path = None
        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {path} ({os.path.getsize(path) / 1024 / 1024:.1f} MB)")
                break

        if model_path is None:
            print("âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œåˆ›å»ºè™šæ‹Ÿæ¨¡å‹...")
            if MODEL_IMPORT_SUCCESS:
                model = EmotionRecognitionModel(num_classes=7, model_name='resnet18', pretrained=False)
                model.to(device)
                model.eval()
                print("âœ… è™šæ‹Ÿæ¨¡å‹åˆ›å»ºæˆåŠŸ")
            else:
                print("âŒ æ— æ³•åˆ›å»ºæ¨¡å‹ï¼ˆæ¨¡å‹æ¨¡å—å¯¼å…¥å¤±è´¥ï¼‰")
                model = None
        else:
            # åŠ è½½çœŸå®æ¨¡å‹
            if MODEL_IMPORT_SUCCESS:
                model = load_model(model_path, model_name='resnet18', num_classes=7, device=device)
                print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print("âŒ æ— æ³•åŠ è½½æ¨¡å‹ï¼ˆæ¨¡å‹æ¨¡å—å¯¼å…¥å¤±è´¥ï¼‰")
                model = None

    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        model = None

    # å®šä¹‰å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    print("âœ… å›¾åƒé¢„å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    return model is not None


def initialize_health_advisor():
    """åˆå§‹åŒ–å¥åº·å»ºè®®ç”Ÿæˆå™¨"""
    global health_advisor
    print("\n" + "=" * 70)
    print("ğŸ§  åˆå§‹åŒ–å¥åº·å»ºè®®ç”Ÿæˆå™¨")
    print("=" * 70)

    try:
        if HEALTH_ADVISOR_IMPORT_SUCCESS:
            # æŸ¥æ‰¾è§„åˆ™æ–‡ä»¶
            rules_path = os.path.join(PROJECT_ROOT, 'advice_rules.json')
            if os.path.exists(rules_path):
                print(f"âœ… æ‰¾åˆ°è§„åˆ™æ–‡ä»¶: {rules_path}")
                health_advisor = HealthAdvisor(rules_path=rules_path)
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°è§„åˆ™æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™")
                health_advisor = HealthAdvisor()
            print("âœ… å¥åº·å»ºè®®ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        else:
            print("âŒ å¥åº·å»ºè®®æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œæ— æ³•åˆå§‹åŒ–")
            health_advisor = None
            return False
    except Exception as e:
        print(f"âŒ å¥åº·å»ºè®®ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        health_advisor = None
        return False


# def predict_emotion(image):
#     """
#     é¢„æµ‹å›¾åƒä¸­çš„è¡¨æƒ…
#     Args:
#         image: PIL Image å¯¹è±¡
#     Returns:
#         tuple: (emotion, confidence, probabilities)
#     """
#     # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
#     if model is None:
#         # è¿”å›æ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
#         print("âš ï¸  ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆæ¨¡å‹æœªåŠ è½½ï¼‰")
#         return 'happy', 0.80, {
#     'anger': 0.04,
#     'disgust': 0.03,
#     'fear': 0.02,
#     'happy': 0.80,
#     'neutral': 0.05,
#     'sad': 0.03,
#     'surprised': 0.03,
# }
#
#     try:
#         # é¢„å¤„ç†å›¾åƒ
#         img_tensor = transform(image).unsqueeze(0).to(device)
#
#         # æ¨ç†
#         with torch.no_grad():
#             outputs = model(img_tensor)
#             probabilities = torch.softmax(outputs, dim=1)[0]
#             predicted_idx = torch.argmax(probabilities).item()
#             confidence = probabilities[predicted_idx].item()
#
#         emotion = EMOTION_LABELS[predicted_idx]
#
#         # æ„é€ æ¦‚ç‡å­—å…¸
#         prob_dict = {
#             EMOTION_LABELS[i]: float(probabilities[i])
#             for i in range(len(EMOTION_LABELS))
#         }
#
#         print(f"ğŸ” é¢„æµ‹ç»“æœ: {emotion} ({confidence:.2%})")
#         return emotion, confidence, prob_dict
#
#     except Exception as e:
#         print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
#         # è¿”å›æ¨¡æ‹Ÿæ•°æ®
#         return 'happy', 0.80, {
#     'anger': 0.04,
#     'disgust': 0.03,
#     'fear': 0.02,
#     'happy': 0.80,
#     'neutral': 0.05,
#     'sad': 0.03,
#     'surprised': 0.03
# }
def predict_emotion(image):
    try:
        # 1. è½¬æ¢å›¾åƒæ ¼å¼
        img_cv2 = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        h, w = img_cv2.shape[:2]

        # 2. å¦‚æœä¹‹å‰ MediaPipe æŠ¥é”™ï¼Œæˆ‘ä»¬è¿™é‡Œç›´æ¥ç”¨ OpenCV çš„åº•å±‚æ£€æµ‹
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬å…ˆå°è¯•æœ€ç¨³çš„æ£€æµ‹
        gray = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2GRAY)
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)

        if len(faces) > 0:
            # å–é¢ç§¯æœ€å¤§çš„è„¸
            (x, y, fw, fh) = max(faces, key=lambda b: b[2] * b[3])
            # æ‰©å¤§äººè„¸æ¡†ï¼ˆè®©æ¨¡å‹çœ‹å…¨ä¸€ç‚¹ï¼‰
            pad = int(fw * 0.2)
            face_img = image.crop((max(0, x - pad), max(0, y - pad), min(w, x + fw + pad), min(h, y + fh + pad)))
            print(f"âœ… æˆåŠŸå®šä½äººè„¸åŒºåŸŸ: {x},{y}")
        else:
            face_img = image
            print("âš ï¸ æœªæ£€æµ‹åˆ°äººè„¸ï¼Œä½¿ç”¨å…¨å›¾")

        # 3. æ¨¡å‹é¢„æµ‹
        img_tensor = transform(face_img).unsqueeze(0).to(device)
        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.softmax(outputs, dim=1)[0]
            idx = torch.argmax(probs).item()

        return EMOTION_LABELS[idx], float(probs[idx]), {EMOTION_LABELS[i]: float(probs[i]) for i in
                                                        range(len(EMOTION_LABELS))}
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        return 'neutral', 0.0, {}

# ================ åŸºç¡€APIç«¯ç‚¹ ================
@app.route('/')
def home():
    """API é¦–é¡µ - æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨ç«¯ç‚¹"""
    endpoints = {
        'åŸºç¡€ç«¯ç‚¹': {
            'GET /': 'APIä¿¡æ¯ï¼ˆå½“å‰é¡µé¢ï¼‰',
            'GET /health': 'å¥åº·æ£€æŸ¥',
            'GET /emotions': 'è·å–æ”¯æŒçš„è¡¨æƒ…åˆ—è¡¨'
        },
        'è¡¨æƒ…è¯†åˆ«': {
            'POST /predict': 'å•å¼ å›¾åƒè¡¨æƒ…è¯†åˆ«',
            'POST /predict_with_advice': 'è¡¨æƒ…è¯†åˆ«+å¥åº·å»ºè®®'
        },
        'æ‘„åƒå¤´ç›‘æµ‹': {
            'GET /monitor/status': 'è·å–ç›‘æµ‹å™¨çŠ¶æ€',
            'POST /monitor/start': 'å¼€å§‹ç›‘æµ‹',
            'POST /monitor/pause': 'æš‚åœç›‘æµ‹',
            'POST /monitor/resume': 'ç»§ç»­ç›‘æµ‹',
            'POST /monitor/stop': 'åœæ­¢ç›‘æµ‹',
            'GET /monitor/analyze': 'åˆ†æå†å²æ•°æ®'
        },
        'AIå¤§æ¨¡å‹åˆ†æ': {
            'POST /comprehensive_analysis': 'ç»¼åˆæƒ…ç»ªåˆ†æå¹¶è°ƒç”¨é˜¿é‡Œäº‘å¤§æ¨¡å‹'
        }
    }

    return jsonify({
        'success': True,
        'message': 'è¡¨æƒ…è¯†åˆ«ä¸å¥åº·å»ºè®® API - AIå¤§æ¨¡å‹å¢å¼ºç‰ˆ',
        'version': '4.0.0',
        'timestamp': datetime.now().isoformat(),
        'endpoints': endpoints,
        'model_loaded': model is not None,
        'health_advisor_loaded': health_advisor is not None,
        'llm_available': OPENAI_AVAILABLE,
        'device': str(device) if device else 'unknown'
    })


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model is not None,
        'health_advisor_loaded': health_advisor is not None,
        'llm_available': OPENAI_AVAILABLE,
        'device': str(device) if device else 'unknown',
        'timestamp': datetime.now().isoformat(),
        'version': '4.0.0'
    })


@app.route('/emotions', methods=['GET'])
def get_emotions():
    """è·å–æ”¯æŒçš„è¡¨æƒ…åˆ—è¡¨"""
    emotions_with_zh = [
        {'en': emo, 'zh': EMOTION_ZH.get(emo, emo)}
        for emo in EMOTION_LABELS
    ]

    return jsonify({
        'success': True,
        'emotions': emotions_with_zh,
        'count': len(EMOTION_LABELS),
        'timestamp': datetime.now().isoformat()
    })


@app.route('/predict', methods=['POST'])
def predict():
    """
    å•å¼ å›¾åƒè¡¨æƒ…è¯†åˆ«
    æ”¯æŒæ ¼å¼: multipart/form-data (æ–‡ä»¶ä¸Šä¼ ) æˆ– application/json (base64)
    """
    try:
        # è·å–å›¾åƒ
        if 'image' in request.files:
            # ä»æ–‡ä»¶ä¸Šä¼ è·å–
            file = request.files['image']
            image_bytes = file.read()
            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')

        elif request.is_json and 'image' in request.json:
            # ä»JSONè·å–base64ç¼–ç çš„å›¾åƒ
            image_data = request.json['image']
            if ',' in image_data:
                image_data = image_data.split(',')[1]
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')

        else:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›å›¾åƒæ–‡ä»¶æˆ–base64ç¼–ç çš„å›¾åƒ',
                'supported_formats': ['multipart/form-data (æ–‡ä»¶)', 'application/json (base64)']
            }), 400

        # é¢„æµ‹è¡¨æƒ…
        emotion, confidence, probabilities = predict_emotion(image)

        return jsonify({
            'success': True,
            'emotion': emotion,
            'emotion_zh': EMOTION_ZH.get(emotion, emotion),
            'confidence': float(confidence),
            'probabilities': probabilities,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ é¢„æµ‹é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/predict_with_advice', methods=['POST'])
def predict_with_advice():
    """
    è¡¨æƒ…è¯†åˆ«å¹¶ç”Ÿæˆå¥åº·å»ºè®®
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶
        if 'image' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æœªæä¾›å›¾åƒæ–‡ä»¶',
                'timestamp': datetime.now().isoformat()
            }), 400

        file = request.files['image']

        # æ£€æŸ¥æ–‡ä»¶å
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'æœªé€‰æ‹©æ–‡ä»¶',
                'timestamp': datetime.now().isoformat()
            }), 400

        # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
        user_context = {}
        if request.form.get('user_context'):
            try:
                user_context = json.loads(request.form['user_context'])
            except:
                user_context = {}

        # è¯»å–å›¾åƒæ•°æ®
        image_bytes = file.read()

        # ç¡®ä¿è¯»å–åˆ°æ•°æ®
        if not image_bytes:
            return jsonify({
                'success': False,
                'error': 'å›¾åƒæ–‡ä»¶ä¸ºç©º',
                'timestamp': datetime.now().isoformat()
            }), 400

        # å°†å­—èŠ‚è½¬æ¢ä¸ºPIL Image
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')

        # è¿›è¡Œæƒ…ç»ªé¢„æµ‹
        emotion, confidence, probabilities = predict_emotion(image)

        # æ„å»ºé¢„æµ‹ç»“æœ
        prediction_result = {
            'emotion': emotion,
            'emotion_zh': EMOTION_ZH.get(emotion, emotion),
            'confidence': float(confidence),
            'probabilities': probabilities,
            'timestamp': datetime.now().isoformat()
        }

        # ç”Ÿæˆå¥åº·å»ºè®®
        if health_advisor is not None and HEALTH_ADVISOR_IMPORT_SUCCESS:
            try:
                # åˆ›å»ºæƒ…ç»ªç»“æœå¯¹è±¡
                emotion_result = EmotionResult(
                    emotion=emotion,
                    confidence=confidence,
                    probabilities=probabilities
                )

                # ç”Ÿæˆå»ºè®®
                health_report = health_advisor.generate_advice(emotion_result, user_context)

                # åˆå¹¶ç»“æœ
                full_result = {
                    "success": True,
                    "prediction": prediction_result,
                    "health_advice_report": health_report,
                    "message": "æˆåŠŸç”Ÿæˆå¥åº·å»ºè®®",
                    "timestamp": datetime.now().isoformat()
                }

                return jsonify(full_result)

            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¥åº·å»ºè®®å¤±è´¥: {e}")
                # è¿”å›ä»…é¢„æµ‹ç»“æœ
                return jsonify({
                    'success': True,
                    'prediction': prediction_result,
                    'health_advice_report': None,
                    'message': 'é¢„æµ‹æˆåŠŸï¼Œä½†å¥åº·å»ºè®®ç”Ÿæˆå¤±è´¥',
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
        else:
            # å¥åº·å»ºè®®æ¨¡å—æœªåŠ è½½
            return jsonify({
                'success': True,
                'prediction': prediction_result,
                'health_advice_report': None,
                'message': 'é¢„æµ‹æˆåŠŸï¼Œä½†å¥åº·å»ºè®®æ¨¡å—æœªåŠ è½½',
                'timestamp': datetime.now().isoformat()
            })

    except Exception as e:
        print(f"âŒ é¢„æµ‹å»ºè®®é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


# ================ æ–°å¢çš„APIç«¯ç‚¹ï¼šç»¼åˆæƒ…ç»ªåˆ†æ ================
@app.route('/comprehensive_analysis', methods=['POST'])
def comprehensive_analysis():
    """
    ç»¼åˆæƒ…ç»ªåˆ†æå¹¶è°ƒç”¨é˜¿é‡Œäº‘å¤§æ¨¡å‹

    è¯·æ±‚ä½“æ ¼å¼:
    {
        "use_history": true,  # æ˜¯å¦ä½¿ç”¨å†å²æ•°æ®
        "analysis_type": "health_advice",  # åˆ†æç±»å‹: health_advice, monitor_analysis, detailed_report
        "days": 7,  # åˆ†ææœ€è¿‘å‡ å¤©æ•°æ®
        "user_context": {  # ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            "age_group": "adult",
            "stress_level": "medium",
            "has_support_system": true,
            "is_first_time": false
        }
    }
    """
    try:
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'è¯·æ±‚å¿…é¡»æ˜¯JSONæ ¼å¼',
                'timestamp': datetime.now().isoformat()
            }), 400

        data = request.get_json()
        use_history = data.get('use_history', True)
        analysis_type = data.get('analysis_type', 'health_advice')
        days = data.get('days', 7)
        user_context = data.get('user_context', {})  # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œé»˜è®¤ä¸ºç©ºå­—å…¸

        print(f"ğŸ” å¼€å§‹ç»¼åˆæƒ…ç»ªåˆ†æ: use_history={use_history}, type={analysis_type}, days={days}")
        print(f"ğŸ‘¤ ç”¨æˆ·ä¸Šä¸‹æ–‡: {user_context}")

        # æ”¶é›†å†å²æ•°æ®
        history_data = []
        if use_history:
            # ä»resultsç›®å½•æ”¶é›†æ‰€æœ‰å†å²æ•°æ®
            results_dir = os.path.join(PROJECT_ROOT, "data", "monitor_results", "results")
            if os.path.exists(results_dir):
                for filename in os.listdir(results_dir):
                    if filename.endswith('.json'):
                        filepath = os.path.join(results_dir, filename)
                        try:
                            with open(filepath, 'r', encoding='utf-8') as f:
                                result = json.load(f)

                                # åªæ”¶é›†æœ€è¿‘dayså¤©çš„æ•°æ®
                                if days:
                                    result_time = datetime.fromisoformat(result['timestamp'].replace('Z', '+00:00'))
                                    cutoff_time = datetime.now() - timedelta(days=days)
                                    if result_time >= cutoff_time:
                                        history_data.append(result)
                                else:
                                    history_data.append(result)
                        except Exception as e:
                            print(f"âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ {filename}: {e}")
                            continue

        print(f"ğŸ“Š æ”¶é›†åˆ° {len(history_data)} æ¡å†å²æ•°æ®")

        # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œä½¿ç”¨ç®—æ³•ç”Ÿæˆæ¨¡æ‹Ÿå»ºè®®
        if not history_data:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å†å²åˆ†ææ•°æ®ï¼Œä½¿ç”¨ç®—æ³•ç”Ÿæˆå»ºè®®")

            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
            history_data = generate_sample_data(10)

            # åˆ†ææ•°æ®ï¼Œç”Ÿæˆæ€»ç»“
            analysis_result = analyze_comprehensive_data(history_data, analysis_type)

            # ä½¿ç”¨ç®—æ³•ç”Ÿæˆå»ºè®®ï¼ˆä¸è°ƒç”¨å¤§æ¨¡å‹ï¼‰
            algorithm_result = generate_algorithm_based_analysis(analysis_result, analysis_type, user_context)

            # ç”Ÿæˆç»¼åˆç»“æœæ–‡ä»¶
            comprehensive_result = {
                'summary': analysis_result,
                'algorithm_analysis': algorithm_result,
                'total_samples': len(history_data),
                'history_data': history_data[:5],  # åªä¿å­˜å‰5æ¡ç”¨äºæ˜¾ç¤º
                'generated_at': datetime.now().isoformat(),
                'analysis_type': analysis_type,
                'user_context': user_context,  # åŒ…å«ç”¨æˆ·ä¸Šä¸‹æ–‡
                'using_algorithm': True,
                'message': 'ä½¿ç”¨ç®—æ³•ç”Ÿæˆå»ºè®®ï¼ˆæ— å†å²æ•°æ®æˆ–å¤§æ¨¡å‹ä¸å¯ç”¨ï¼‰'
            }
        else:
            # åˆ†ææ•°æ®ï¼Œç”Ÿæˆæ€»ç»“
            analysis_result = analyze_comprehensive_data(history_data, analysis_type)

            # å°è¯•è°ƒç”¨é˜¿é‡Œäº‘å¤§æ¨¡å‹
            llm_response = None
            if OPENAI_AVAILABLE:
                llm_response = call_aliyun_llm(analysis_result, analysis_type, user_context)
            else:
                print("âš ï¸  OpenAI SDKä¸å¯ç”¨ï¼Œä½¿ç”¨ç®—æ³•ç”Ÿæˆå»ºè®®")
                llm_response = {
                    'success': False,
                    'error': 'OpenAI SDKä¸å¯ç”¨',
                    'algorithm_analysis': generate_algorithm_based_analysis(analysis_result, analysis_type, user_context)
                }

            # ç”Ÿæˆç»¼åˆç»“æœæ–‡ä»¶
            comprehensive_result = {
                'summary': analysis_result,
                'llm_response': llm_response,
                'total_samples': len(history_data),
                'history_data': history_data[:10],  # åªä¿å­˜å‰10æ¡ç”¨äºæ˜¾ç¤º
                'generated_at': datetime.now().isoformat(),
                'analysis_type': analysis_type,
                'user_context': user_context,  # åŒ…å«ç”¨æˆ·ä¸Šä¸‹æ–‡
                'using_algorithm': not (llm_response and llm_response.get('success', False))
            }

        # ä¿å­˜åˆ°ç»¼åˆç»“æœæ–‡ä»¶ï¼ˆè¦†ç›–ï¼‰
        output_filename = f"comprehensive_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        output_path = os.path.join(COMPREHENSIVE_RESULT_DIR, output_filename)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_result, f, ensure_ascii=False, indent=2)

        print(f"âœ… ç»¼åˆç»“æœå·²ä¿å­˜åˆ°: {output_path}")

        return jsonify({
            'success': True,
            'message': 'ç»¼åˆæƒ…ç»ªåˆ†æå®Œæˆ',
            'data': comprehensive_result,
            'output_file': output_filename,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ ç»¼åˆæƒ…ç»ªåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


def generate_sample_data(num_samples):
    """ç”Ÿæˆç¤ºä¾‹æ•°æ®"""
    sample_data = []
    emotions = ['happy', 'sad', 'anger', 'fear', 'surprised', 'disgust', 'neutral']

    for i in range(num_samples):
        emotion = np.random.choice(emotions)
        confidence = np.random.uniform(0.6, 0.95)

        # ç”Ÿæˆæ¦‚ç‡åˆ†å¸ƒ
        probabilities = {}
        for e in emotions:
            if e == emotion:
                probabilities[e] = confidence
            else:
                probabilities[e] = (1 - confidence) / (len(emotions) - 1)

        sample_data.append({
            'timestamp': (datetime.now() - timedelta(hours=i * 2)).isoformat(),
            'emotion': emotion,
            'emotion_zh': EMOTION_ZH.get(emotion, emotion),
            'confidence': confidence,
            'probabilities': probabilities
        })

    return sample_data


def analyze_comprehensive_data(history_data, analysis_type):
    """åˆ†æç»¼åˆæ•°æ®"""
    # æƒ…ç»ªåˆ†å¸ƒç»Ÿè®¡
    emotion_counts = {}
    emotion_confidences = []
    timestamps = []

    for result in history_data:
        emotion = result.get('emotion', 'unknown')
        confidence = result.get('confidence', 0)

        if emotion not in emotion_counts:
            emotion_counts[emotion] = 0
        emotion_counts[emotion] += 1
        emotion_confidences.append(confidence)
        timestamps.append(result.get('timestamp', ''))

    # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
    avg_confidence = sum(emotion_confidences) / len(emotion_confidences) if emotion_confidences else 0

    # æƒ…ç»ªè¶‹åŠ¿åˆ†æ
    emotion_trend = {}
    if len(timestamps) > 1:
        try:
            # æŒ‰æ—¶é—´æ’åº
            sorted_data = sorted(history_data, key=lambda x: x.get('timestamp', ''))
            # æå–æ—¶é—´åºåˆ—çš„æƒ…ç»ªå˜åŒ–
            emotion_timeseries = []
            for item in sorted_data:
                emotion_timeseries.append({
                    'time': item.get('timestamp', ''),
                    'emotion': item.get('emotion', 'unknown'),
                    'confidence': item.get('confidence', 0)
                })
            emotion_trend['timeseries'] = emotion_timeseries
        except Exception as e:
            print(f"âš ï¸  æƒ…ç»ªè¶‹åŠ¿åˆ†æå¤±è´¥: {e}")

    # ä¸»è¦æƒ…ç»ª
    if emotion_counts:
        dominant_emotion = max(emotion_counts.items(), key=lambda x: x[1])
    else:
        dominant_emotion = ('unknown', 0)

    # æƒ…ç»ªç¨³å®šæ€§è®¡ç®—ï¼ˆåŸºäºæƒ…ç»ªå˜åŒ–çš„é¢‘ç‡ï¼‰
    stability_score = 0
    if len(history_data) > 1:
        emotion_changes = 0
        for i in range(1, len(history_data)):
            if history_data[i].get('emotion') != history_data[i - 1].get('emotion'):
                emotion_changes += 1
        stability_score = max(0, 100 - (emotion_changes / len(history_data) * 100))

    # ç”Ÿæˆåˆ†æç»“æœ
    analysis = {
        'emotion_distribution': emotion_counts,
        'total_samples': len(history_data),
        'average_confidence': avg_confidence,
        'dominant_emotion': {
            'emotion': dominant_emotion[0],
            'emotion_zh': EMOTION_ZH.get(dominant_emotion[0], dominant_emotion[0]),
            'count': dominant_emotion[1],
            'percentage': (dominant_emotion[1] / len(history_data)) * 100 if history_data else 0
        },
        'time_range': {
            'start': min(timestamps) if timestamps else '',
            'end': max(timestamps) if timestamps else ''
        },
        'emotion_trend': emotion_trend,
        'stability_score': stability_score,
        'analysis_type': analysis_type
    }

    # æ ¹æ®åˆ†æç±»å‹æ·»åŠ ç‰¹å®šä¿¡æ¯
    if analysis_type == 'health_advice':
        analysis['health_insights'] = generate_health_insights(emotion_counts, len(history_data))
    elif analysis_type == 'monitor_analysis':
        analysis['monitor_stats'] = generate_monitor_stats(history_data)
    elif analysis_type == 'detailed_report':
        analysis['detailed_analysis'] = generate_detailed_analysis(history_data)

    return analysis


def generate_health_insights(emotion_counts, total_samples):
    """ç”Ÿæˆå¥åº·æ´å¯Ÿ"""
    insights = []

    # è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹
    negative_emotions = ['anger', 'sad', 'fear']
    negative_count = sum(emotion_counts.get(emo, 0) for emo in negative_emotions)
    negative_percentage = (negative_count / total_samples) * 100 if total_samples > 0 else 0

    if negative_percentage > 50:
        insights.append(f"è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹è¾ƒé«˜ ({negative_percentage:.1f}%)ï¼Œå»ºè®®å…³æ³¨æƒ…ç»ªç®¡ç†")
    elif negative_percentage > 30:
        insights.append(f"è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹é€‚ä¸­ ({negative_percentage:.1f}%)ï¼Œå»ºè®®ä¿æŒå…³æ³¨")
    else:
        insights.append(f"è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹è¾ƒä½ ({negative_percentage:.1f}%)ï¼Œæƒ…ç»ªçŠ¶æ€è‰¯å¥½")

    # æ­£é¢æƒ…ç»ª
    positive_emotions = ['happy']
    positive_count = sum(emotion_counts.get(emo, 0) for emo in positive_emotions)
    positive_percentage = (positive_count / total_samples) * 100 if total_samples > 0 else 0

    insights.append(f"å¿«ä¹æƒ…ç»ªå æ¯” {positive_percentage:.1f}%")

    # æƒ…ç»ªå¤šæ ·æ€§
    emotion_diversity = len(emotion_counts)
    if emotion_diversity > 4:
        insights.append("æƒ…ç»ªä½“éªŒä¸°å¯Œï¼Œæƒ…æ„Ÿè¡¨è¾¾å¤šæ ·")
    elif emotion_diversity > 2:
        insights.append("æƒ…ç»ªä½“éªŒè¾ƒä¸ºä¸°å¯Œ")
    else:
        insights.append("æƒ…ç»ªä½“éªŒè¾ƒä¸ºå•ä¸€")

    return insights


def generate_monitor_stats(history_data):
    """ç”Ÿæˆç›‘æµ‹ç»Ÿè®¡"""
    stats = {
        'total_captures': len(history_data),
        'time_period': 'æœªçŸ¥',
        'capture_frequency': 'æœªçŸ¥',
        'success_rate': '100%'
    }

    if len(history_data) > 1:
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            timestamps = [datetime.fromisoformat(r['timestamp'].replace('Z', '+00:00')) for r in history_data]
            time_diff = max(timestamps) - min(timestamps)
            stats['time_period'] = f"{time_diff.days}å¤©{time_diff.seconds // 3600}å°æ—¶"

            # è®¡ç®—å¹³å‡æ•è·é¢‘ç‡
            if len(timestamps) > 2:
                intervals = []
                for i in range(1, len(timestamps)):
                    interval = (timestamps[i] - timestamps[i - 1]).total_seconds()
                    intervals.append(interval)
                avg_interval = sum(intervals) / len(intervals)
                if avg_interval < 60:
                    stats['capture_frequency'] = f"å¹³å‡æ¯{avg_interval:.0f}ç§’ä¸€æ¬¡"
                else:
                    stats['capture_frequency'] = f"å¹³å‡æ¯{avg_interval / 60:.1f}åˆ†é’Ÿä¸€æ¬¡"
        except:
            pass

    return stats


def generate_detailed_analysis(history_data):
    """ç”Ÿæˆè¯¦ç»†åˆ†æ"""
    analysis = {
        'emotion_transitions': [],
        'confidence_analysis': {
            'min': 0,
            'max': 0,
            'avg': 0
        },
        'patterns': [],
        'recommendations': []
    }

    if history_data:
        # è®¡ç®—ç½®ä¿¡åº¦ç»Ÿè®¡
        confidences = [r.get('confidence', 0) for r in history_data]
        analysis['confidence_analysis'] = {
            'min': min(confidences),
            'max': max(confidences),
            'avg': sum(confidences) / len(confidences)
        }

        # æ£€æµ‹æƒ…ç»ªè½¬æ¢
        if len(history_data) > 1:
            emotions = [r.get('emotion', 'unknown') for r in history_data]
            transitions = []
            for i in range(1, len(emotions)):
                if emotions[i] != emotions[i - 1]:
                    from_emo = EMOTION_ZH.get(emotions[i - 1], emotions[i - 1])
                    to_emo = EMOTION_ZH.get(emotions[i], emotions[i])
                    transitions.append(f"{from_emo} â†’ {to_emo}")
            analysis['emotion_transitions'] = transitions[:5]  # åªæ˜¾ç¤ºå‰5ä¸ª

        # æ£€æµ‹æ¨¡å¼
        emotion_counts = {}
        for result in history_data:
            emotion = result.get('emotion', 'unknown')
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

        # è¯†åˆ«å¸¸è§æ¨¡å¼
        total = len(history_data)
        for emotion, count in emotion_counts.items():
            percentage = (count / total) * 100
            if percentage > 60:
                analysis['patterns'].append(f"ä¸»è¦æƒ…ç»ªæ¨¡å¼: {EMOTION_ZH.get(emotion, emotion)} (å æ¯”{percentage:.1f}%)")
            elif percentage > 30:
                analysis['patterns'].append(f"æ¬¡è¦æƒ…ç»ªæ¨¡å¼: {EMOTION_ZH.get(emotion, emotion)} (å æ¯”{percentage:.1f}%)")

        # ç”Ÿæˆå»ºè®®
        if analysis['confidence_analysis']['avg'] > 0.8:
            analysis['recommendations'].append("æƒ…ç»ªè¯†åˆ«ç½®ä¿¡åº¦é«˜ï¼Œåˆ†æç»“æœå¯é ")
        else:
            analysis['recommendations'].append("æƒ…ç»ªè¯†åˆ«ç½®ä¿¡åº¦ä¸­ç­‰ï¼Œå»ºè®®å¤šæ¬¡ç›‘æµ‹è·å–æ›´å‡†ç¡®ç»“æœ")

        if len(analysis['emotion_transitions']) > 5:
            analysis['recommendations'].append("æƒ…ç»ªå˜åŒ–é¢‘ç¹ï¼Œå»ºè®®å…³æ³¨æƒ…ç»ªç¨³å®šæ€§")

    return analysis


def generate_algorithm_based_analysis(analysis_result, analysis_type, user_context=None):
    """ä½¿ç”¨ç®—æ³•ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆå½“å¤§æ¨¡å‹ä¸å¯ç”¨æ—¶ï¼‰"""

    emotion_counts = analysis_result.get('emotion_distribution', {})
    total_samples = analysis_result.get('total_samples', 0)
    dominant_emotion = analysis_result.get('dominant_emotion', {})
    stability_score = analysis_result.get('stability_score', 0)

    dominant_emotion_name = dominant_emotion.get('emotion_zh', 'æœªçŸ¥')
    dominant_percentage = dominant_emotion.get('percentage', 0)

    # è®¡ç®—è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹
    negative_emotions = ['anger', 'sad', 'fear']
    negative_count = sum(emotion_counts.get(emo, 0) for emo in negative_emotions)
    negative_percentage = (negative_count / total_samples) * 100 if total_samples > 0 else 0

    # è®¡ç®—æ­£é¢æƒ…ç»ªæ¯”ä¾‹
    positive_emotions = ['happy']
    positive_count = sum(emotion_counts.get(emo, 0) for emo in positive_emotions)
    positive_percentage = (positive_count / total_samples) * 100 if total_samples > 0 else 0

    # æ ¹æ®ç”¨æˆ·ä¸Šä¸‹æ–‡è°ƒæ•´åˆ†æ
    age_group = user_context.get('age_group', 'adult') if user_context else 'adult'
    stress_level = user_context.get('stress_level', 'medium') if user_context else 'medium'
    has_support = user_context.get('has_support_system', True) if user_context else True
    is_first_time = user_context.get('is_first_time', False) if user_context else False

    # æ ¹æ®å¹´é¾„ç»„è°ƒæ•´å»ºè®®
    age_specific_advice = []
    if age_group == 'child':
        age_specific_advice.extend([
            "å»ºè®®å®¶é•¿å¤šå…³æ³¨å­©å­çš„æƒ…ç»ªå˜åŒ–",
            "é¼“åŠ±å­©å­ç”¨ç»˜ç”»æˆ–æ¸¸æˆè¡¨è¾¾æƒ…ç»ª",
            "å»ºç«‹è§„å¾‹çš„ä½œæ¯å’Œæƒ…ç»ªè¡¨è¾¾ä¹ æƒ¯"
        ])
    elif age_group == 'teen':
        age_specific_advice.extend([
            "é’æ˜¥æœŸçš„æƒ…ç»ªæ³¢åŠ¨æ˜¯æ­£å¸¸çš„",
            "é¼“åŠ±ä¸æœ‹å‹æˆ–å®¶é•¿åˆ†äº«æ„Ÿå—",
            "åŸ¹å…»å¥åº·çš„å…´è¶£çˆ±å¥½"
        ])
    elif age_group == 'elder':
        age_specific_advice.extend([
            "ä¿æŒç¤¾äº¤æ´»åŠ¨ï¼Œé¿å…å­¤ç‹¬",
            "é€‚åº¦è¿åŠ¨ï¼Œä¿æŒèº«å¿ƒå¥åº·",
            "å‚ä¸ç¤¾åŒºæ´»åŠ¨æˆ–å¿—æ„¿å·¥ä½œ"
        ])

    # æ ¹æ®å‹åŠ›æ°´å¹³è°ƒæ•´å»ºè®®
    stress_specific_advice = []
    if stress_level == 'high':
        stress_specific_advice.extend([
            "é«˜å‹åŠ›çŠ¶æ€ä¸‹éœ€è¦ç‰¹åˆ«æ³¨æ„æƒ…ç»ªè°ƒèŠ‚",
            "æ¯å¤©å®‰æ’15-30åˆ†é’Ÿçš„æ”¾æ¾æ—¶é—´",
            "å­¦ä¹ å‹åŠ›ç®¡ç†æŠ€å·§"
        ])

    # æ ¹æ®æ”¯æŒç³»ç»Ÿè°ƒæ•´å»ºè®®
    support_specific_advice = []
    if not has_support:
        support_specific_advice.extend([
            "å»ºè®®ä¸»åŠ¨å»ºç«‹ç¤¾äº¤æ”¯æŒç½‘ç»œ",
            "å‚åŠ å…´è¶£å°ç»„æˆ–ç¤¾åŒºæ´»åŠ¨",
            "è€ƒè™‘å¯»æ±‚ä¸“ä¸šå¿ƒç†å’¨è¯¢"
        ])
    else:
        support_specific_advice.extend([
            "å–„ç”¨ç°æœ‰çš„ç¤¾ä¼šæ”¯æŒç³»ç»Ÿ",
            "ä¸ä¿¡ä»»çš„äººåˆ†äº«æƒ…ç»ªä½“éªŒ",
            "åœ¨éœ€è¦æ—¶å¯»æ±‚äº²å‹å¸®åŠ©"
        ])

    # æ ¹æ®ä½¿ç”¨ç»éªŒè°ƒæ•´å»ºè®®
    experience_specific_advice = []
    if is_first_time:
        experience_specific_advice.extend([
            "æ¬¢è¿é¦–æ¬¡ä½¿ç”¨æƒ…ç»ªç›‘æµ‹ç³»ç»Ÿ",
            "å»ºè®®è¿ç»­ä½¿ç”¨1-2å‘¨å»ºç«‹æƒ…ç»ªåŸºçº¿",
            "è®°å½•æƒ…ç»ªè§¦å‘äº‹ä»¶ä»¥ä¾¿åˆ†æ"
        ])
    else:
        experience_specific_advice.extend([
            "ç»§ç»­åšæŒæƒ…ç»ªç›‘æµ‹å’Œè®°å½•",
            "å¯¹æ¯”å†å²æ•°æ®è§‚å¯Ÿå˜åŒ–è¶‹åŠ¿",
            "æ ¹æ®å»ºè®®è°ƒæ•´æƒ…ç»ªç®¡ç†ç­–ç•¥"
        ])

    if analysis_type == 'health_advice':
        # å¥åº·å»ºè®®ç®—æ³•
        risk_level = "ä½"
        if negative_percentage > 50:
            risk_level = "é«˜"
        elif negative_percentage > 30:
            risk_level = "ä¸­"

        advice = {
            'overall_assessment': f"åŸºäº{total_samples}æ¡æ•°æ®åˆ†æï¼Œä¸»è¦æƒ…ç»ªä¸º{dominant_emotion_name} (å æ¯”{dominant_percentage:.1f}%)",
            'risk_assessment': {
                'level': risk_level,
                'description': f"è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹{negative_percentage:.1f}%ï¼Œæƒ…ç»ªç¨³å®šæ€§{stability_score:.1f}%",
                'negative_percentage': negative_percentage,
                'positive_percentage': positive_percentage
            },
            'immediate_actions': [
                "æ·±å‘¼å¸10æ¬¡ï¼Œæ”¾æ¾èº«å¿ƒ",
                "çŸ­æš‚ç¦»å¼€å½“å‰ç¯å¢ƒï¼Œè½¬ç§»æ³¨æ„åŠ›",
                "å–ä¸€æ¯æ¸©æ°´ï¼Œå¹³å¤æƒ…ç»ª",
                "è¿›è¡Œ2åˆ†é’Ÿçš„æ‹‰ä¼¸è¿åŠ¨"
            ],
            'daily_tips': [
                              "æ¯å¤©è®°å½•æƒ…ç»ªå˜åŒ–ï¼Œè¯†åˆ«è§¦å‘å› ç´ ",
                              "ä¿æŒè§„å¾‹ä½œæ¯ï¼Œä¿è¯7-8å°æ—¶ç¡çœ ",
                              "æ¯å¤©è¿›è¡Œ30åˆ†é’Ÿæœ‰æ°§è¿åŠ¨",
                              "ç»ƒä¹ æ­£å¿µå†¥æƒ³æˆ–å‘¼å¸è®­ç»ƒ"
                          ] + age_specific_advice[:2] + stress_specific_advice[:2],
            'long_term_suggestions': [
                                         "å­¦ä¹ æƒ…ç»ªç®¡ç†æŠ€å·§ï¼ˆå¦‚è®¤çŸ¥è¡Œä¸ºç–—æ³•ï¼‰",
                                         "å»ºç«‹å¥åº·çš„ç”Ÿæ´»ä¹ æƒ¯",
                                         "åŸ¹å…»ç§¯æçš„æ€ç»´æ–¹å¼",
                                         "å®šæœŸè¿›è¡Œå¿ƒç†å¥åº·è‡ªæˆ‘è¯„ä¼°"
                                     ] + support_specific_advice + experience_specific_advice,
            'user_context_notes': {
                'age_group': age_group,
                'stress_level': stress_level,
                'has_support_system': has_support,
                'is_first_time': is_first_time
            },
            'algorithm_based': True
        }
        return advice

    elif analysis_type == 'monitor_analysis':
        # ç›‘æµ‹åˆ†æç®—æ³•
        stability_text = "ç¨³å®š" if stability_score > 70 else ("ä¸­ç­‰" if stability_score > 40 else "æ³¢åŠ¨å¤§")
        frequency_advice = "å»ºè®®ä¿æŒå½“å‰ç›‘æµ‹é¢‘ç‡" if stability_score > 60 else "å»ºè®®å¢åŠ ç›‘æµ‹é¢‘ç‡ä»¥è·å¾—æ›´å‡†ç¡®æ•°æ®"

        analysis = {
            'summary': f"ç›‘æµ‹æ•°æ®åˆ†ææŠ¥å‘Š - å…±{total_samples}æ¡æ•°æ®",
            'key_findings': [
                f"ä¸»è¦æƒ…ç»ª: {dominant_emotion_name} (å æ¯”{dominant_percentage:.1f}%)",
                f"æƒ…ç»ªç¨³å®šæ€§: {stability_score:.1f}% ({stability_text})",
                f"è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹: {negative_percentage:.1f}%",
                f"æ­£é¢æƒ…ç»ªæ¯”ä¾‹: {positive_percentage:.1f}%"
            ],
            'monitoring_insights': [
                f"æ•°æ®é‡‡é›†æ•°é‡: {total_samples}æ¡",
                f"æƒ…ç»ªå¤šæ ·æ€§: {len(emotion_counts)}ç§ä¸åŒæƒ…ç»ª",
                f"ä¸»è¦æƒ…ç»ªæŒç»­æ€§: {'è¾ƒå¼º' if dominant_percentage > 50 else 'ä¸€èˆ¬'}"
            ],
            'user_specific_recommendations': age_specific_advice + support_specific_advice + experience_specific_advice,
            'monitoring_recommendations': [
                frequency_advice,
                "åœ¨ä¸åŒæ—¶é—´æ®µè¿›è¡Œç›‘æµ‹ä»¥è·å¾—æ›´å…¨é¢çš„æ•°æ®",
                "è®°å½•æƒ…ç»ªè§¦å‘äº‹ä»¶ä»¥ä¾¿åˆ†æ",
                "è®¾ç½®æƒ…ç»ªå˜åŒ–æé†’å’Œé¢„è­¦"
            ],
            'algorithm_based': True
        }
        return analysis

    elif analysis_type == 'detailed_report':
        # è¯¦ç»†æŠ¥å‘Šç®—æ³•
        emotion_diversity = len(emotion_counts)
        diversity_text = "ä¸°å¯Œ" if emotion_diversity > 4 else ("é€‚ä¸­" if emotion_diversity > 2 else "å•ä¸€")

        # æƒ…ç»ªè½¬æ¢åˆ†æ
        emotion_transitions = []
        if total_samples > 1:
            try:
                # è·å–å†å²æ•°æ®ä¸­çš„æƒ…ç»ªåºåˆ—
                emotions_sequence = []
                if analysis_result.get('emotion_trend', {}).get('timeseries'):
                    for item in analysis_result['emotion_trend']['timeseries']:
                        emotions_sequence.append(item.get('emotion', 'unknown'))

                if len(emotions_sequence) > 1:
                    for i in range(1, len(emotions_sequence)):
                        if emotions_sequence[i] != emotions_sequence[i - 1]:
                            from_emo = EMOTION_ZH.get(emotions_sequence[i - 1], emotions_sequence[i - 1])
                            to_emo = EMOTION_ZH.get(emotions_sequence[i], emotions_sequence[i])
                            emotion_transitions.append(f"{from_emo} â†’ {to_emo}")
            except:
                pass

        report = {
            'title': f"è¯¦ç»†æƒ…ç»ªåˆ†ææŠ¥å‘Š - {total_samples}æ¡æ•°æ®",
            'executive_summary': f"åŸºäºæ•°æ®åˆ†æï¼Œæ‚¨çš„ä¸»è¦æƒ…ç»ªæ¨¡å¼ä¸º{dominant_emotion_name}ï¼Œæƒ…ç»ªä½“éªŒ{diversity_text}ï¼Œç¨³å®šæ€§{stability_score:.1f}%ã€‚",
            'demographic_considerations': f"è€ƒè™‘åˆ°æ‚¨çš„å¹´é¾„ç»„ä¸º{age_group}ï¼Œå‹åŠ›æ°´å¹³ä¸º{stress_level}ï¼Œä»¥ä¸‹å»ºè®®é’ˆå¯¹æ‚¨çš„ä¸ªäººæƒ…å†µå®šåˆ¶ã€‚",
            'detailed_analysis': [
                f"æƒ…ç»ªåˆ†å¸ƒ: {', '.join([f'{EMOTION_ZH.get(e, e)}: {c}æ¬¡ ({c / total_samples * 100:.1f}%)' for e, c in emotion_counts.items()])}",
                f"æƒ…ç»ªç¨³å®šæ€§è¯„åˆ†: {stability_score:.1f}/100",
                f"æƒ…ç»ªå¤šæ ·æ€§: {emotion_diversity}ç§ä¸åŒæƒ…ç»ª",
                f"è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹: {negative_percentage:.1f}%",
                f"æ­£é¢æƒ…ç»ªæ¯”ä¾‹: {positive_percentage:.1f}%"
            ],
            'pattern_analysis': [
                f"ä¸»è¦æƒ…ç»ªæ¨¡å¼: {dominant_emotion_name} (å‡ºç°{dominant_emotion.get('count', 0)}æ¬¡)",
                f"æƒ…ç»ªå˜åŒ–é¢‘ç‡: {len(emotion_transitions)}æ¬¡æ˜æ˜¾æƒ…ç»ªè½¬æ¢" if emotion_transitions else "æƒ…ç»ªå˜åŒ–è¾ƒå°‘",
                f"æƒ…ç»ªè½¬æ¢æ¨¡å¼: {'ã€'.join(emotion_transitions[:3])}" if emotion_transitions else "æ— æ˜æ˜¾è½¬æ¢æ¨¡å¼"
            ],
            'professional_insights': [
                                         "æƒ…ç»ªæ¨¡å¼æ˜¾ç¤ºç›¸å¯¹ç¨³å®šï¼Œå»ºè®®ç»§ç»­ä¿æŒæƒ…ç»ªç®¡ç†ä¹ æƒ¯",
                                         "å¦‚æœ‰è´Ÿé¢æƒ…ç»ªæŒç»­å‡ºç°ï¼Œå»ºè®®å…³æ³¨å¹¶é€‚å½“è°ƒæ•´åº”å¯¹ç­–ç•¥",
                                         "æƒ…ç»ªå¤šæ ·æ€§æœ‰åŠ©äºæƒ…æ„Ÿå¥åº·å‘å±•å’Œå¿ƒç†å¼¹æ€§æå‡"
                                     ] + age_specific_advice,
            'personalized_recommendations': [
                                                "å»ºç«‹ä¸ªäººæƒ…ç»ªæ—¥è®°ï¼Œè®°å½•æ¯æ—¥æƒ…ç»ªå˜åŒ–åŠåŸå› ",
                                                "å­¦ä¹ æ­£å¿µå†¥æƒ³æŠ€å·§ï¼Œæé«˜æƒ…ç»ªè§‰å¯Ÿå’Œè‡ªæˆ‘è°ƒèŠ‚èƒ½åŠ›",
                                                "æ ¹æ®æƒ…ç»ªæ¨¡å¼è°ƒæ•´æ—¥å¸¸ç”Ÿæ´»èŠ‚å¥å’Œæ´»åŠ¨å®‰æ’",
                                                "å®šæœŸå›é¡¾æƒ…ç»ªæ•°æ®ï¼Œè¯†åˆ«æ”¹å–„è¶‹åŠ¿å’Œæ½œåœ¨é—®é¢˜"
                                            ] + support_specific_advice + stress_specific_advice,
            'follow_up_suggestions': [
                                         "å»ºè®®æ¯2å‘¨è¿›è¡Œä¸€æ¬¡ç»¼åˆæƒ…ç»ªåˆ†æ",
                                         "åœ¨æƒ…ç»ªæ³¢åŠ¨è¾ƒå¤§æ—¶å¢åŠ ç›‘æµ‹é¢‘ç‡",
                                         "å°†æƒ…ç»ªæ•°æ®ä¸ç”Ÿæ´»äº‹ä»¶å…³è”åˆ†æ",
                                         "è€ƒè™‘ä¸å¿ƒç†å¥åº·ä¸“ä¸šäººå£«åˆ†äº«åˆ†æç»“æœ"
                                     ] + experience_specific_advice,
            'algorithm_based': True
        }
        return report

    return {"error": "æœªçŸ¥åˆ†æç±»å‹", "algorithm_based": True}


# ================ ä¿®æ”¹ call_aliyun_llm å‡½æ•°å®šä¹‰ ================
def call_aliyun_llm(analysis_result, analysis_type, user_context=None):
    """
    è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°å¤§æ¨¡å‹
    ä½¿ç”¨å…¼å®¹OpenAIçš„SDK
    """
    try:
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAI SDK æœªå®‰è£…ï¼Œæ— æ³•è°ƒç”¨å¤§æ¨¡å‹")

        # ä»ç¯å¢ƒå˜é‡è·å–API Key
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise ValueError("æœªè®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ï¼Œæ— æ³•è°ƒç”¨å¤§æ¨¡å‹")

        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client = OpenAI(
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )

        print(f"ğŸ“¤ è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼å¤§æ¨¡å‹ï¼Œåˆ†æç±»å‹: {analysis_type}")

        # æ„å»ºæç¤ºè¯ - æ·»åŠ  user_context å‚æ•°
        prompt = build_llm_prompt(analysis_result, analysis_type, user_context)

        # é€‰æ‹©æ¨¡å‹
        model_name = "qwen-plus"  # æˆ– "qwen-max", "qwen-turbo"

        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": build_system_prompt(analysis_type, user_context)
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        # è°ƒç”¨æ¨¡å‹
        completion = client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )

        # è·å–å›å¤
        llm_response = completion.choices[0].message.content

        print(f"âœ… å¤§æ¨¡å‹è°ƒç”¨æˆåŠŸï¼Œå›å¤é•¿åº¦: {len(llm_response)}")

        return {
            'success': True,
            'model': model_name,
            'raw_response': llm_response,
            'usage': {
                'total_tokens': completion.usage.total_tokens if completion.usage else 0,
                'prompt_tokens': completion.usage.prompt_tokens if completion.usage else 0,
                'completion_tokens': completion.usage.completion_tokens if completion.usage else 0
            }
        }

    except Exception as e:
        print(f"âŒ è°ƒç”¨é˜¿é‡Œäº‘å¤§æ¨¡å‹å¤±è´¥: {e}")
        return {
            'success': False,
            'error': str(e),
            'fallback': generate_algorithm_based_analysis(analysis_result, analysis_type)
        }


def build_system_prompt(analysis_type, user_context=None):
    """æ„å»ºç³»ç»Ÿæç¤ºè¯"""

    # åŸºç¡€ç³»ç»Ÿæç¤º
    base_prompts = {
        'health_advice': """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å¥åº·é¡¾é—®ï¼Œæ“…é•¿æƒ…ç»ªåˆ†æå’Œå¥åº·å»ºè®®ã€‚
è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æƒ…ç»ªè¯†åˆ«æ•°æ®å’Œç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼Œæä¾›ä¸“ä¸šã€å…·ä½“ã€å¯æ“ä½œçš„å¥åº·å»ºè®®ã€‚
ä½ çš„å»ºè®®åº”è¯¥ï¼š
1. åŸºäºæ•°æ®äº‹å®ï¼Œå®¢è§‚åˆ†æ
2. ç»“åˆç”¨æˆ·çš„å…·ä½“æƒ…å†µæä¾›ä¸ªæ€§åŒ–å»ºè®®
3. æä¾›å…·ä½“å¯æ“ä½œçš„å»ºè®®
4. è€ƒè™‘ä¸åŒæƒ…ç»ªçŠ¶æ€çš„å¿ƒç†å½±å“
5. å¿…è¦æ—¶æä¾›ç´§æ€¥å»ºè®®
6. ä½¿ç”¨ä¸­æ–‡å›å¤ï¼Œç»“æ„æ¸…æ™°ï¼Œæ˜“äºç†è§£""",

        'monitor_analysis': """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æƒ…ç»ªæ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿æƒ…ç»ªç›‘æµ‹æ•°æ®åˆ†æã€‚
è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æƒ…ç»ªç›‘æµ‹æ•°æ®ï¼Œæä¾›ä¸“ä¸šçš„åˆ†ææŠ¥å‘Šã€‚
ä½ çš„åˆ†æåº”è¯¥ï¼š
1. åŸºäºæ•°æ®è¶‹åŠ¿ï¼Œå®¢è§‚åˆ†æ
2. è¯†åˆ«å¼‚å¸¸æ¨¡å¼å’Œæ½œåœ¨é—®é¢˜
3. è€ƒè™‘ç”¨æˆ·çš„å…·ä½“æƒ…å†µæä¾›ç›‘æµ‹å»ºè®®
4. é¢„æµ‹å¯èƒ½çš„æƒ…ç»ªå˜åŒ–è¶‹åŠ¿
5. ä½¿ç”¨ä¸­æ–‡å›å¤ï¼Œç»“æ„æ¸…æ™°ï¼Œæ•°æ®é©±åŠ¨""",

        'detailed_report': """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¿ƒç†å­¦ä¸“å®¶ï¼Œæ“…é•¿æƒ…ç»ªæ¨¡å¼è¯†åˆ«å’Œæ·±åº¦åˆ†æã€‚
è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„è¯¦ç»†æƒ…ç»ªæ•°æ®ï¼Œæä¾›ä¸“ä¸šçš„å¿ƒç†å­¦åˆ†ææŠ¥å‘Šã€‚
ä½ çš„æŠ¥å‘Šåº”è¯¥ï¼š
1. æ·±å…¥åˆ†ææƒ…ç»ªæ¨¡å¼å’ŒèƒŒåçš„å¿ƒç†å› ç´ 
2. ç»“åˆç”¨æˆ·æƒ…å†µæä¾›ä¸“ä¸šè§£è¯»
3. æä¾›ä¸ªæ€§åŒ–çš„å‘å±•å»ºè®®
4. å…³æ³¨æƒ…ç»ªå¥åº·å’Œé•¿æœŸå‘å±•
5. ä½¿ç”¨ä¸­æ–‡å›å¤ï¼Œä¸“ä¸šä¸”æœ‰æ·±åº¦"""
    }

    system_prompt = base_prompts.get(analysis_type,
                                     "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å¥åº·é¡¾é—®ï¼Œè¯·æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯æä¾›ä¸“ä¸šçš„åˆ†æå’Œå»ºè®®ã€‚")

    # å¦‚æœæœ‰ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ åˆ°ç³»ç»Ÿæç¤ºè¯ä¸­
    if user_context and isinstance(user_context, dict) and len(user_context) > 0:
        user_info = "\n\n## ç”¨æˆ·ä¸ªäººä¿¡æ¯\n"

        # å¹´é¾„ç»„æ˜ å°„
        if user_context.get('age_group'):
            age_groups = {
                'child': 'å„¿ç«¥ (0-12å²)',
                'teen': 'é’å°‘å¹´ (13-19å²)',
                'adult': 'æˆäºº (20-59å²)',
                'elder': 'è€å¹´äºº (60å²ä»¥ä¸Š)'
            }
            user_info += f"- å¹´é¾„ç»„: {age_groups.get(user_context['age_group'], user_context['age_group'])}\n"

        # å‹åŠ›æ°´å¹³æ˜ å°„
        if user_context.get('stress_level'):
            stress_levels = {
                'low': 'ä½å‹åŠ›',
                'medium': 'ä¸­ç­‰å‹åŠ›',
                'high': 'é«˜å‹åŠ›'
            }
            user_info += f"- å‹åŠ›æ°´å¹³: {stress_levels.get(user_context['stress_level'], user_context['stress_level'])}\n"

        # æ”¯æŒç³»ç»Ÿ
        if user_context.get('has_support_system') is not None:
            has_support = user_context['has_support_system']
            user_info += f"- ç¤¾ä¼šæ”¯æŒç³»ç»Ÿ: {'æœ‰ (æœ‰äº²å‹æ”¯æŒ)' if has_support else 'æ—  (ç¼ºä¹ç¤¾ä¼šæ”¯æŒ)'}\n"

        # æ˜¯å¦é¦–æ¬¡ä½¿ç”¨
        if user_context.get('is_first_time') is not None:
            is_first_time = user_context['is_first_time']
            user_info += f"- ä½¿ç”¨ç»éªŒ: {'é¦–æ¬¡ä½¿ç”¨æƒ…ç»ªç›‘æµ‹ç³»ç»Ÿ' if is_first_time else 'æœ‰æƒ…ç»ªç›‘æµ‹ç»éªŒ'}\n"

        # èŒä¸šç±»å‹ï¼ˆå¯é€‰å­—æ®µï¼‰
        if user_context.get('occupation'):
            occupations = {
                'student': 'å­¦ç”Ÿ',
                'office_worker': 'ä¸Šç­æ—',
                'freelancer': 'è‡ªç”±èŒä¸šè€…',
                'retired': 'é€€ä¼‘äººå‘˜'
            }
            user_info += f"- èŒä¸šç±»å‹: {occupations.get(user_context['occupation'], user_context['occupation'])}\n"

        # è¿‘æœŸæ´»åŠ¨ï¼ˆå¯é€‰å­—æ®µï¼‰
        if user_context.get('recent_activity'):
            user_info += f"- è¿‘æœŸä¸»è¦æ´»åŠ¨: {user_context['recent_activity']}\n"

        user_info += "\nè¯·æ ¹æ®ä»¥ä¸Šç”¨æˆ·ä¿¡æ¯ï¼Œç»“åˆæƒ…ç»ªæ•°æ®åˆ†æç»“æœï¼Œæä¾›æ›´åŠ ä¸ªæ€§åŒ–ã€é’ˆå¯¹æ€§çš„åˆ†æå’Œå»ºè®®ã€‚"

        system_prompt += user_info

    return system_prompt


def build_llm_prompt(analysis_result, analysis_type, user_context=None):
    """æ„å»ºå¤§æ¨¡å‹æç¤ºè¯"""

    prompt = f"""
    è¯·æ ¹æ®ä»¥ä¸‹æƒ…ç»ªè¯†åˆ«æ•°æ®åˆ†æç»“æœï¼Œæä¾›ä¸“ä¸šçš„åˆ†æå’Œå»ºè®®ï¼š

    ## æ•°æ®åˆ†ææ‘˜è¦
    - æ€»æ ·æœ¬æ•°: {analysis_result.get('total_samples', 0)}
    - æƒ…ç»ªåˆ†å¸ƒ: {json.dumps(analysis_result.get('emotion_distribution', {}), ensure_ascii=False)}
    - ä¸»è¦æƒ…ç»ª: {analysis_result.get('dominant_emotion', {}).get('emotion_zh', 'æœªçŸ¥')} (å æ¯”{analysis_result.get('dominant_emotion', {}).get('percentage', 0):.1f}%)
    - å¹³å‡ç½®ä¿¡åº¦: {analysis_result.get('average_confidence', 0):.2%}
    - æƒ…ç»ªç¨³å®šæ€§: {analysis_result.get('stability_score', 0):.1f}%
    - æ—¶é—´èŒƒå›´: {analysis_result.get('time_range', {}).get('start', 'æœªçŸ¥')} è‡³ {analysis_result.get('time_range', {}).get('end', 'æœªçŸ¥')}

    """

    # æ·»åŠ å¥åº·æ´å¯Ÿï¼ˆå¦‚æœæœ‰ï¼‰
    if analysis_type == 'health_advice' and 'health_insights' in analysis_result:
        prompt += f"## å¥åº·æ´å¯Ÿ\n"
        for insight in analysis_result['health_insights']:
            prompt += f"- {insight}\n"
        prompt += "\n"

    if analysis_type == 'health_advice':
        prompt += """
        è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®ï¼Œæä¾›ï¼š
        1. æ•´ä½“æƒ…ç»ªçŠ¶æ€è¯„ä¼°
        2. å…·ä½“çš„å¥åº·å»ºè®®ï¼ˆç«‹å³è¡ŒåŠ¨ã€æ—¥å¸¸è´´å£«ã€é•¿æœŸå»ºè®®ï¼‰
        3. é£é™©è¯„ä¼°
        4. å¦‚æœ‰éœ€è¦ï¼Œæä¾›ç´§æ€¥å»ºè®®
        """
    elif analysis_type == 'monitor_analysis':
        prompt += """
        è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®ï¼Œæä¾›ï¼š
        1. ç›‘æµ‹æ•°æ®åˆ†æ
        2. æƒ…ç»ªå˜åŒ–è¶‹åŠ¿
        3. å¼‚å¸¸æ¨¡å¼æ£€æµ‹
        4. ç›‘æµ‹å»ºè®®
        """
    elif analysis_type == 'detailed_report':
        prompt += """
        è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®ï¼Œæä¾›ï¼š
        1. è¯¦ç»†æƒ…ç»ªåˆ†ææŠ¥å‘Š
        2. æƒ…ç»ªæ¨¡å¼è¯†åˆ«
        3. ä¸“ä¸šå¿ƒç†å­¦è§£è¯»
        4. ä¸ªæ€§åŒ–å»ºè®®
        """

    prompt += """

    è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œç»“æ„æ¸…æ™°ï¼Œä¸“ä¸šä¸”æ˜“äºç†è§£ã€‚
    """

    return prompt


# ================ æ‘„åƒå¤´ç›‘æµ‹APIç«¯ç‚¹ ================
# é¦–å…ˆï¼Œå¦‚æœå¯¼å…¥æ‘„åƒå¤´ç›‘æµ‹æ¨¡å—å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„ç›‘æµ‹å™¨
try:
    # å°è¯•ä»apiç›®å½•å¯¼å…¥
    from api.camera_monitor import get_monitor

    CAMERA_MONITOR_IMPORT_SUCCESS = True
    print("âœ… æˆåŠŸå¯¼å…¥æ‘„åƒå¤´ç›‘æµ‹æ¨¡å—")
except ImportError as e:
    print(f"âš ï¸  å¯¼å…¥æ‘„åƒå¤´ç›‘æµ‹æ¨¡å—å¤±è´¥: {e}")
    print("   åˆ›å»ºè™šæ‹Ÿæ‘„åƒå¤´ç›‘æµ‹æ¨¡å—")

    CAMERA_MONITOR_IMPORT_SUCCESS = False


    # åˆ›å»ºè™šæ‹Ÿçš„æ‘„åƒå¤´ç›‘æµ‹å™¨ç±»
    class VirtualCameraMonitor:
        def __init__(self, model_path=None, save_dir="monitor_results"):
            self.model_path = model_path
            self.save_dir = save_dir
            self.is_monitoring = False
            self.total_captures = 0
            self.successful_analyses = 0
            self.capture_interval = 5
            self.camera_index = 0

            # åˆ›å»ºä¿å­˜ç›®å½•
            results_dir = os.path.join(save_dir, "results")
            os.makedirs(results_dir, exist_ok=True)

        def get_status(self):
            return {
                "is_monitoring": self.is_monitoring,
                "total_captures": self.total_captures,
                "successful_analyses": self.successful_analyses,
                "capture_interval": self.capture_interval,
                "camera_index": self.camera_index
            }

        def start(self, camera_index=0, capture_interval=5):
            self.camera_index = camera_index
            self.capture_interval = capture_interval
            self.is_monitoring = True

            # æ¨¡æ‹Ÿæ‘„åƒå¤´å¯åŠ¨
            print(f"ğŸ“· è™šæ‹Ÿæ‘„åƒå¤´ç›‘æµ‹å·²å¯åŠ¨ (æ‘„åƒå¤´ç´¢å¼•: {camera_index}, æŠ“æ‹é—´éš”: {capture_interval}ç§’)")

            return {"status": "started", "message": "è™šæ‹Ÿç›‘æµ‹æ¨¡å¼ - æ‘„åƒå¤´åŠŸèƒ½éœ€è¦å®‰è£…OpenCV"}

        def pause(self):
            self.is_monitoring = False
            return {"status": "paused"}

        def resume(self):
            self.is_monitoring = True
            return {"status": "resumed"}

        def stop(self):
            self.is_monitoring = False
            return {"status": "stopped"}

        def analyze_history(self):
            # æ¨¡æ‹Ÿåˆ†æå†å²æ•°æ®
            return {"status": "analysis_completed", "message": "è™šæ‹Ÿåˆ†æå®Œæˆ"}


    def get_monitor(model_path=None, save_dir="monitor_results"):
        return VirtualCameraMonitor(model_path=model_path, save_dir=save_dir)

monitor = None


def initialize_camera_monitor():
    """åˆå§‹åŒ–æ‘„åƒå¤´ç›‘æµ‹å™¨"""
    global monitor
    print("\n" + "=" * 70)
    print("ğŸ“· åˆå§‹åŒ–æ‘„åƒå¤´ç›‘æµ‹å™¨")
    print("=" * 70)

    try:
        # è®¾ç½®ä¿å­˜ç›®å½•
        save_dir = os.path.join(PROJECT_ROOT, "data", "monitor_results")

        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        model_path = None
        possible_paths = [
            os.path.join(PROJECT_ROOT, 'best_model.pth'),
            os.path.join(PROJECT_ROOT, 'models', 'best_model.pth')
        ]

        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                print(f"âœ… æ‰¾åˆ°ç›‘æµ‹æ¨¡å‹: {path}")
                break

        monitor = get_monitor(model_path=model_path, save_dir=save_dir)
        print("âœ… æ‘„åƒå¤´ç›‘æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ‘„åƒå¤´ç›‘æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        monitor = None
        return False


@app.route('/monitor/status', methods=['GET'])
def get_monitor_status():
    """è·å–ç›‘æµ‹å™¨çŠ¶æ€"""
    try:
        if monitor is None:
            return jsonify({
                'success': False,
                'error': 'ç›‘æµ‹å™¨æœªåˆå§‹åŒ–',
                'timestamp': datetime.now().isoformat()
            }), 500

        status = monitor.get_status()

        return jsonify({
            'success': True,
            'status': status,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        print(f"âŒ è·å–ç›‘æµ‹å™¨çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/monitor/start', methods=['POST'])
def start_monitor():
    """å¼€å§‹æ‘„åƒå¤´ç›‘æµ‹"""
    try:
        if monitor is None:
            return jsonify({
                'success': False,
                'error': 'ç›‘æµ‹å™¨æœªåˆå§‹åŒ–',
                'timestamp': datetime.now().isoformat()
            }), 500

        # è·å–è¯·æ±‚å‚æ•°
        if request.is_json:
            data = request.get_json()
            camera_index = data.get('camera_index', 0)
            capture_interval = data.get('capture_interval', 5)
        else:
            camera_index = request.form.get('camera_index', 0, type=int)
            capture_interval = request.form.get('capture_interval', 5, type=int)

        # æ£€æŸ¥OpenCVæ˜¯å¦å¯ç”¨
        if not CV2_AVAILABLE:
            print("âš ï¸  OpenCVä¸å¯ç”¨ï¼Œä½¿ç”¨è™šæ‹Ÿç›‘æµ‹æ¨¡å¼")

        # è°ƒç”¨ç›‘æµ‹å™¨çš„startæ–¹æ³•
        result = monitor.start(camera_index=camera_index, capture_interval=capture_interval)

        return jsonify({
            'success': True,
            'message': 'æ‘„åƒå¤´ç›‘æµ‹å·²å¯åŠ¨',
            'camera_index': camera_index,
            'capture_interval': capture_interval,
            'result': result,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ å¯åŠ¨ç›‘æµ‹å™¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/monitor/pause', methods=['POST'])
def pause_monitor():
    """æš‚åœæ‘„åƒå¤´ç›‘æµ‹"""
    try:
        if monitor is None:
            return jsonify({
                'success': False,
                'error': 'ç›‘æµ‹å™¨æœªåˆå§‹åŒ–',
                'timestamp': datetime.now().isoformat()
            }), 500

        result = monitor.pause()
        return jsonify({
            'success': True,
            'message': 'æ‘„åƒå¤´ç›‘æµ‹å·²æš‚åœ',
            'result': result,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ æš‚åœç›‘æµ‹å™¨å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/monitor/resume', methods=['POST'])
def resume_monitor():
    """ç»§ç»­æ‘„åƒå¤´ç›‘æµ‹"""
    try:
        if monitor is None:
            return jsonify({
                'success': False,
                'error': 'ç›‘æµ‹å™¨æœªåˆå§‹åŒ–',
                'timestamp': datetime.now().isoformat()
            }), 500

        result = monitor.resume()
        return jsonify({
            'success': True,
            'message': 'æ‘„åƒå¤´ç›‘æµ‹å·²ç»§ç»­',
            'result': result,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ ç»§ç»­ç›‘æµ‹å™¨å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/monitor/stop', methods=['POST'])
def stop_monitor():
    """åœæ­¢æ‘„åƒå¤´ç›‘æµ‹"""
    try:
        if monitor is None:
            return jsonify({
                'success': False,
                'error': 'ç›‘æµ‹å™¨æœªåˆå§‹åŒ–',
                'timestamp': datetime.now().isoformat()
            }), 500

        result = monitor.stop()
        return jsonify({
            'success': True,
            'message': 'æ‘„åƒå¤´ç›‘æµ‹å·²åœæ­¢',
            'result': result,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ åœæ­¢ç›‘æµ‹å™¨å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/monitor/analyze', methods=['GET'])
def analyze_monitor_data():
    """åˆ†æç›‘æµ‹å†å²æ•°æ®"""
    try:
        # å¦‚æœæ²¡æœ‰ç›‘æµ‹å™¨ï¼Œå°è¯•ä»ä¿å­˜çš„æ–‡ä»¶ä¸­åˆ†æ
        results_dir = os.path.join(PROJECT_ROOT, "data", "monitor_results", "results")
        if not os.path.exists(results_dir):
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°ç›‘æµ‹å†å²æ•°æ®',
                'timestamp': datetime.now().isoformat()
            }), 404

        # æ”¶é›†æ‰€æœ‰ç»“æœæ–‡ä»¶
        results = []
        for filename in os.listdir(results_dir):
            if filename.endswith('.json'):
                filepath = os.path.join(results_dir, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        result = json.load(f)
                        results.append(result)
                except Exception as e:
                    print(f"âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ {filename}: {e}")
                    continue

        if not results:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æœ‰æ•ˆçš„ç›‘æµ‹æ•°æ®',
                'timestamp': datetime.now().isoformat()
            }), 404

        # åˆ†ææ•°æ®
        emotion_counts = {}
        emotion_confidences = {}
        total_results = len(results)

        for result in results:
            emotion = result.get('emotion', 'unknown')
            confidence = result.get('confidence', 0)

            if emotion not in emotion_counts:
                emotion_counts[emotion] = 0
                emotion_confidences[emotion] = []
            emotion_counts[emotion] += 1
            emotion_confidences[emotion].append(confidence)

        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        avg_confidences = {}
        for emotion, conf_list in emotion_confidences.items():
            avg_confidences[emotion] = sum(conf_list) / len(conf_list)

        # æ‰¾åˆ°ä¸»è¦æƒ…ç»ª
        if emotion_counts:
            dominant_emotion = max(emotion_counts.items(), key=lambda x: x[1])
            dominant_emotion_name = dominant_emotion[0]
            dominant_count = dominant_emotion[1]
            dominant_percentage = (dominant_count / total_results) * 100
        else:
            dominant_emotion_name = 'unknown'
            dominant_percentage = 0

        analysis = {
            'emotion_distribution': emotion_counts,
            'average_confidences': avg_confidences,
            'dominant_emotion': {
                'emotion': dominant_emotion_name,
                'emotion_zh': EMOTION_ZH.get(dominant_emotion_name, dominant_emotion_name),
                'count': dominant_count if emotion_counts else 0,
                'percentage': dominant_percentage
            },
            'total_results': total_results
        }

        return jsonify({
            'success': True,
            'analysis': analysis,
            'total_results': total_results,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ åˆ†æç›‘æµ‹æ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


# ================ å¯åŠ¨æœåŠ¡å™¨ ================
if __name__ == '__main__':
    print("\n" + "=" * 70)
    print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
    print("=" * 70)

    # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
    model_initialized = initialize_model()
    health_initialized = initialize_health_advisor()
    camera_initialized = initialize_camera_monitor()

    print("\n" + "=" * 70)
    print("âœ… åˆå§‹åŒ–å®Œæˆ")
    print("=" * 70)

    print(f"ğŸ“Š åˆå§‹åŒ–çŠ¶æ€:")
    print(f"  è¡¨æƒ…è¯†åˆ«æ¨¡å‹: {'âœ… å·²åŠ è½½' if model_initialized else 'âŒ æœªåŠ è½½'}")
    print(f"  å¥åº·å»ºè®®æ¨¡å—: {'âœ… å·²åŠ è½½' if health_initialized else 'âŒ æœªåŠ è½½'}")
    print(f"  æ‘„åƒå¤´ç›‘æµ‹å™¨: {'âœ… å·²åŠ è½½' if camera_initialized else 'âŒ æœªåŠ è½½'}")
    print(f"  é˜¿é‡Œäº‘å¤§æ¨¡å‹: {'âœ… å¯ç”¨' if OPENAI_AVAILABLE else 'âŒ ä¸å¯ç”¨'}")

    print("\n" + "=" * 70)
    print("ğŸŒ API æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print("=" * 70)

    print(f"ğŸ“Œ è®¿é—®åœ°å€: http://0.0.0.0:7860")
    print(f"ğŸ“Œ å¥åº·æ£€æŸ¥: http://0.0.0.0:7860/health")
    print(f"ğŸ“Œ æƒ…ç»ªåˆ—è¡¨: http://0.0.0.0:7860/emotions")

    print(f"\nğŸ”§ æµ‹è¯•å‘½ä»¤:")
    print(f"  curl http://0.0.0.0:7860/health")
    print(f"  curl http://0.0.0.0:7860/emotions")
    print(
        f"  curl -X POST http://0.0.0.0:7860/comprehensive_analysis -H 'Content-Type: application/json' -d '{{\"analysis_type\":\"health_advice\",\"days\":7}}'")

    print(f"\nâš ï¸  æ³¨æ„:")
    print(f"  é˜¿é‡Œäº‘å¤§æ¨¡å‹API Key: {'å·²è®¾ç½®' if os.getenv('DASHSCOPE_API_KEY') else 'æœªè®¾ç½®ï¼ˆéœ€åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½® DASHSCOPE_API_KEYï¼‰'}")
    print(f"  ç»¼åˆæƒ…ç»ªåˆ†æç«¯ç‚¹: POST /comprehensive_analysis")
    print("=" * 70)

    # å¯åŠ¨FlaskæœåŠ¡å™¨
    app.run(host='0.0.0.0', port=7860, debug=False, use_reloader=False)