"""
USBæ‘„åƒå¤´ç›‘æµ‹å™¨ - ä¿®å¤ç‰ˆæœ¬
"""

import sys
import os
import time
import threading
import json
from datetime import datetime
from PIL import Image
import torch
import torchvision.transforms as transforms

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# æ£€æŸ¥ OpenCV
try:
    import cv2

    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âš ï¸  OpenCV ä¸å¯ç”¨ï¼Œæ‘„åƒå¤´åŠŸèƒ½å°†è¢«ç¦ç”¨")

# å°è¯•å¯¼å…¥æ¨¡å‹
try:
    from models.emotion_model import load_model, EmotionRecognitionModel

    MODEL_AVAILABLE = True
except ImportError:
    MODEL_AVAILABLE = False
    print("âš ï¸  æ¨¡å‹æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")


class USBCameraMonitor:
    """USBæ‘„åƒå¤´ç›‘æµ‹å™¨"""

    def __init__(self, model_path=None, capture_interval=5, save_dir="data/monitor_results"):
        self.capture_interval = capture_interval
        self.save_dir = save_dir

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        os.makedirs(os.path.join(save_dir, "images"), exist_ok=True)
        os.makedirs(os.path.join(save_dir, "results"), exist_ok=True)

        # ç›‘æµ‹çŠ¶æ€
        self.is_monitoring = False
        self.is_paused = False
        self.total_captures = 0
        self.successful_analyses = 0
        self.camera = None
        self.monitor_thread = None

        # è®¾å¤‡è®¾ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ“± ç›‘æµ‹å™¨è®¾å¤‡: {self.device}")

        # å°è¯•åŠ è½½æ¨¡å‹
        self.model = None
        if model_path and os.path.exists(model_path) and MODEL_AVAILABLE:
            try:
                self.model = load_model(model_path, model_name='resnet18', num_classes=7, device=self.device)
                print("âœ… ç›‘æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.model = None

        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

        # æƒ…ç»ªæ˜ å°„
        self.emotion_zh = {
            'anger': 'æ„¤æ€’',
            'disgust': 'åŒæ¶',
            'fear': 'ææƒ§',
            'happy': 'å¿«ä¹',
            'sad': 'æ‚²ä¼¤',
            'surprised': 'æƒŠè®¶',
            'neutral': 'å¹³é™'
        }

        print(f"ğŸ“‚ ç›‘æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼Œä¿å­˜ç›®å½•: {os.path.abspath(save_dir)}")

    def check_camera(self, camera_index=0):
        """æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦å¯ç”¨"""
        if not CV2_AVAILABLE:
            return False, "OpenCV æœªå®‰è£…"

        try:
            # å°è¯•ä¸åŒçš„åç«¯
            cap = cv2.VideoCapture(camera_index + cv2.CAP_DSHOW)  # Windows

            if not cap.isOpened():
                return False, f"æ‘„åƒå¤´ {camera_index} æ— æ³•æ‰“å¼€"

            # æµ‹è¯•è¯»å–ä¸€å¸§
            ret, frame = cap.read()
            cap.release()

            if ret:
                return True, f"æ‘„åƒå¤´ {camera_index} å¯ç”¨"
            else:
                return False, f"æ‘„åƒå¤´ {camera_index} æ— æ³•è¯»å–å›¾åƒ"

        except Exception as e:
            return False, f"æ‘„åƒå¤´æ£€æŸ¥å¼‚å¸¸: {str(e)}"

    def start_monitoring(self, camera_index=0):
        """å¼€å§‹ç›‘æµ‹"""
        if not CV2_AVAILABLE:
            print("âŒ OpenCV ä¸å¯ç”¨ï¼Œæ— æ³•å¯åŠ¨æ‘„åƒå¤´")
            return False

        if self.is_monitoring:
            print("âš ï¸  ç›‘æµ‹å·²åœ¨è¿è¡Œä¸­")
            return True

        # æ£€æŸ¥æ‘„åƒå¤´
        success, message = self.check_camera(camera_index)
        if not success:
            print(f"âŒ {message}")
            return False

        try:
            print(f"ğŸš€ æ­£åœ¨æ‰“å¼€æ‘„åƒå¤´ {camera_index}...")

            # æ‰“å¼€æ‘„åƒå¤´
            self.camera = cv2.VideoCapture(camera_index + cv2.CAP_DSHOW)

            if not self.camera.isOpened():
                print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                return False

            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, 15)

            width = int(self.camera.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT))
            print(f"âœ… æ‘„åƒå¤´å·²æ‰“å¼€: {width}x{height}")

            self.is_monitoring = True
            self.is_paused = False

            # å¯åŠ¨ç›‘æµ‹çº¿ç¨‹
            self.monitor_thread = threading.Thread(
                target=self._monitoring_loop,
                args=(camera_index,),
                daemon=True
            )
            self.monitor_thread.start()

            print(f"ğŸ¬ ç›‘æµ‹å·²å¯åŠ¨ï¼Œé—´éš”: {self.capture_interval}ç§’")
            return True

        except Exception as e:
            print(f"âŒ å¯åŠ¨ç›‘æµ‹å¤±è´¥: {e}")
            if self.camera:
                self.camera.release()
                self.camera = None
            return False

    def _monitoring_loop(self, camera_index):
        """ç›‘æµ‹å¾ªç¯"""
        print(f"ğŸ” ç›‘æµ‹å¾ªç¯å¼€å§‹ (æ‘„åƒå¤´: {camera_index})")

        while self.is_monitoring:
            try:
                if self.is_paused:
                    time.sleep(0.5)
                    continue

                # è¯»å–æ‘„åƒå¤´å¸§
                ret, frame = self.camera.read()
                if not ret:
                    print("âš ï¸  è¯»å–æ‘„åƒå¤´å¤±è´¥")
                    time.sleep(1)
                    continue

                # ä¿å­˜å›¾åƒ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
                image_filename = f"capture_{timestamp}.jpg"
                image_path = os.path.join(self.save_dir, "images", image_filename)

                # ä¿å­˜å›¾åƒæ–‡ä»¶
                try:
                    success = cv2.imwrite(image_path, frame)
                    if success:
                        self.total_captures += 1
                        print(f"ğŸ“¸ ä¿å­˜ç¬¬ {self.total_captures} å¼ å›¾ç‰‡")

                        # åˆ†æå›¾åƒ
                        result = self._analyze_image(frame, timestamp, image_filename)

                        if result:
                            self.successful_analyses += 1
                            self._save_result(result, timestamp, image_filename)

                            emotion = result.get('emotion_zh', 'æœªçŸ¥')
                            confidence = result.get('confidence', 0)
                            print(f"âœ… åˆ†æå®Œæˆ: {emotion} ({confidence:.1%})")

                    else:
                        print(f"âŒ ä¿å­˜å›¾ç‰‡å¤±è´¥: {image_path}")

                except Exception as e:
                    print(f"âŒ ä¿å­˜å›¾ç‰‡å¼‚å¸¸: {e}")

                # ç­‰å¾…æŒ‡å®šçš„é—´éš”æ—¶é—´
                time.sleep(self.capture_interval)

            except Exception as e:
                print(f"âŒ ç›‘æµ‹å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(1)

    def _analyze_image(self, frame, timestamp, image_filename):
        """åˆ†æå›¾åƒ"""
        try:
            if self.model is None:
                # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                import random
                emotions = ['anger', 'disgust', 'fear', 'happy', 'sad', 'surprised']
                main_emotion = random.choice(emotions)
                confidence = random.uniform(0.6, 0.95)

                probabilities = {}
                for emotion in emotions:
                    if emotion == main_emotion:
                        probabilities[emotion] = confidence
                    else:
                        probabilities[emotion] = (1 - confidence) / (len(emotions) - 1)
            else:
                # ä½¿ç”¨çœŸå®æ¨¡å‹åˆ†æ
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(rgb_frame)

                # é¢„å¤„ç†
                img_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)

                # æ¨ç†
                with torch.no_grad():
                    outputs = self.model(img_tensor)
                    probabilities_tensor = torch.softmax(outputs, dim=1)[0]
                    predicted_idx = torch.argmax(probabilities_tensor).item()
                    confidence = probabilities_tensor[predicted_idx].item()

                emotions_list = list(self.emotion_zh.keys())
                main_emotion = emotions_list[predicted_idx]

                # æ„å»ºæ¦‚ç‡å­—å…¸
                probabilities = {}
                for i, emotion in enumerate(emotions_list):
                    probabilities[emotion] = float(probabilities_tensor[i])

            # æ„å»ºç»“æœ
            result = {
                'timestamp': datetime.now().isoformat(),
                'emotion': main_emotion,
                'emotion_zh': self.emotion_zh.get(main_emotion, main_emotion),
                'confidence': float(confidence),
                'probabilities': probabilities,
                'image_filename': image_filename,
                'image_path': f"images/{image_filename}"
            }

            return result

        except Exception as e:
            print(f"âŒ å›¾åƒåˆ†æå¤±è´¥: {e}")
            return None

    def _save_result(self, result, timestamp, image_filename):
        """ä¿å­˜ç»“æœ"""
        try:
            result_filename = f"result_{timestamp}.json"
            result_path = os.path.join(self.save_dir, "results", result_filename)

            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {result_filename}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def pause_monitoring(self):
        """æš‚åœç›‘æµ‹"""
        if self.is_monitoring and not self.is_paused:
            self.is_paused = True
            print("â¸ï¸ ç›‘æµ‹å·²æš‚åœ")
            return True
        return False

    def resume_monitoring(self):
        """ç»§ç»­ç›‘æµ‹"""
        if self.is_monitoring and self.is_paused:
            self.is_paused = False
            print("â–¶ï¸ ç›‘æµ‹å·²ç»§ç»­")
            return True
        return False

    def stop_monitoring(self):
        """åœæ­¢ç›‘æµ‹"""
        if self.is_monitoring:
            print("ğŸ›‘ æ­£åœ¨åœæ­¢ç›‘æµ‹...")
            self.is_monitoring = False
            self.is_paused = False

            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if self.monitor_thread and self.monitor_thread.is_alive():
                self.monitor_thread.join(timeout=2)
                print("âœ… ç›‘æµ‹çº¿ç¨‹å·²åœæ­¢")

            # å…³é—­æ‘„åƒå¤´
            if self.camera:
                self.camera.release()
                self.camera = None
                print("âœ… æ‘„åƒå¤´å·²é‡Šæ”¾")

            print(f"ğŸ“Š ç»Ÿè®¡: å…±æŠ“æ‹ {self.total_captures} å¼ ï¼ŒæˆåŠŸåˆ†æ {self.successful_analyses} å¼ ")
            return True
        return False

    def get_status(self):
        """è·å–çŠ¶æ€"""
        return {
            'is_monitoring': self.is_monitoring,
            'is_paused': self.is_paused,
            'total_captures': self.total_captures,
            'successful_analyses': self.successful_analyses,
            'capture_interval': self.capture_interval,
            'save_dir': os.path.abspath(self.save_dir),
            'camera_available': CV2_AVAILABLE,
            'camera_opened': self.camera is not None and hasattr(self.camera, 'isOpened') and self.camera.isOpened(),
            'model_loaded': self.model is not None
        }

    def analyze_history(self, days=None):
        """åˆ†æå†å²æ•°æ®"""
        results_dir = os.path.join(self.save_dir, "results")

        if not os.path.exists(results_dir):
            return {
                'success': False,
                'error': 'æ²¡æœ‰å†å²æ•°æ®',
                'total_results': 0
            }

        try:
            # è¯»å–æ‰€æœ‰ç»“æœæ–‡ä»¶
            all_results = []
            for filename in os.listdir(results_dir):
                if filename.endswith('.json'):
                    filepath = os.path.join(results_dir, filename)
                    try:
                        with open(filepath, 'r', encoding='utf-8') as f:
                            result = json.load(f)
                            all_results.append(result)
                    except:
                        continue

            if not all_results:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰åˆ†æç»“æœ',
                    'total_results': 0
                }

            # ç®€å•åˆ†æ
            emotion_counts = {}
            for result in all_results:
                emotion = result.get('emotion', 'unknown')
                emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

            return {
                'success': True,
                'total_results': len(all_results),
                'analysis': {
                    'emotion_distribution': emotion_counts,
                    'total_samples': len(all_results)
                },
                'summary': f"å…±åˆ†æ {len(all_results)} æ¡å†å²æ•°æ®"
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'total_results': 0
            }


# å…¨å±€ç›‘æµ‹å™¨å®ä¾‹
usb_monitor_instance = None


def get_usb_monitor():
    """è·å–USBæ‘„åƒå¤´ç›‘æµ‹å™¨å®ä¾‹"""
    global usb_monitor_instance

    if usb_monitor_instance is None:
        print("ğŸ”„ åˆ›å»ºUSBæ‘„åƒå¤´ç›‘æµ‹å™¨...")

        # è®¾ç½®ä¿å­˜ç›®å½•
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        save_dir = os.path.join(base_dir, "data", "monitor_results")

        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        model_path = None
        possible_paths = [
            os.path.join(base_dir, 'best_model.pth'),
            os.path.join(base_dir, 'models', 'best_model.pth')
        ]

        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {path}")
                break

        usb_monitor_instance = USBCameraMonitor(
            model_path=model_path,
            save_dir=save_dir
        )

        print("âœ… USBæ‘„åƒå¤´ç›‘æµ‹å™¨åˆ›å»ºå®Œæˆ")

    return usb_monitor_instance


if __name__ == "__main__":
    print("USBæ‘„åƒå¤´ç›‘æµ‹å™¨æµ‹è¯•")
    monitor = get_usb_monitor()
    print(monitor.get_status())