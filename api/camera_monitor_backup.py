"""
æ‘„åƒå¤´å®æ—¶ç›‘æµ‹æ¨¡å— - USBæ‘„åƒå¤´å®Œæ•´ä¿®å¤ç‰ˆ
ç”¨äºæ§åˆ¶USBæ‘„åƒå¤´æ‹ç…§å’Œä¿å­˜ç»“æœ
"""

import sys
import os
import time
import threading
import json
from datetime import datetime
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ================ æ£€æŸ¥ OpenCV ================
try:
    import cv2

    CV2_AVAILABLE = True
    print(f"âœ… OpenCV ç‰ˆæœ¬: {cv2.__version__}")
except ImportError as e:
    CV2_AVAILABLE = False
    print(f"âŒ æ— æ³•å¯¼å…¥ OpenCV: {e}")
    print("è¯·è¿è¡Œ: pip install opencv-python")

# ================ æ£€æŸ¥æ¨¡å‹ ================
try:
    from models.emotion_model import load_model, EmotionRecognitionModel

    MODEL_AVAILABLE = True
    print("âœ… æˆåŠŸå¯¼å…¥è¡¨æƒ…è¯†åˆ«æ¨¡å‹")
except ImportError as e:
    MODEL_AVAILABLE = False
    print(f"âŒ å¯¼å…¥è¡¨æƒ…è¯†åˆ«æ¨¡å‹å¤±è´¥: {e}")


    # åˆ›å»ºè™šæ‹Ÿæ¨¡å‹ç±»
    class EmotionRecognitionModel:
        def __init__(self, *args, **kwargs):
            pass

        def eval(self):
            pass

        def to(self, device):
            return self


    def load_model(*args, **kwargs):
        return EmotionRecognitionModel()

# ================ å¯¼å…¥å…¶ä»–æ¨¡å— ================
from PIL import Image
import torch
import torchvision.transforms as transforms


class CameraMonitor:
    """USBæ‘„åƒå¤´ç›‘æµ‹å™¨"""

    def __init__(self, model_path=None, capture_interval=5, save_dir="data/monitor_results"):
        """
        åˆå§‹åŒ–æ‘„åƒå¤´ç›‘æµ‹å™¨

        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            capture_interval: æŠ“æ‹é—´éš”ï¼ˆç§’ï¼‰
            save_dir: ä¿å­˜ç›®å½•
        """
        self.capture_interval = capture_interval
        self.save_dir = save_dir

        # æ£€æŸ¥OpenCVå¯ç”¨æ€§
        if not CV2_AVAILABLE:
            print("âš ï¸  OpenCVæœªå®‰è£…ï¼Œæ‘„åƒå¤´åŠŸèƒ½ä¸å¯ç”¨")
            print("è¯·è¿è¡Œ: pip install opencv-python")
            self.camera_available = False
        else:
            self.camera_available = True

        # ç›‘æµ‹çŠ¶æ€
        self.is_monitoring = False
        self.is_paused = False
        self.total_captures = 0
        self.successful_analyses = 0
        self.camera = None
        self.monitor_thread = None

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        os.makedirs(os.path.join(save_dir, "images"), exist_ok=True)
        os.makedirs(os.path.join(save_dir, "results"), exist_ok=True)

        # è®¾å¤‡è®¾ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ“± ç›‘æµ‹å™¨ä½¿ç”¨è®¾å¤‡: {self.device}")

        # å°è¯•åŠ è½½æ¨¡å‹
        self.model = None
        if model_path and os.path.exists(model_path) and MODEL_AVAILABLE:
            try:
                self.model = load_model(model_path, model_name='resnet18', num_classes=7, device=self.device)
                print("âœ… ç›‘æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.model = None

        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

        # æƒ…ç»ªæ˜ å°„
        self.emotion_zh = {
            'anger': 'æ„¤æ€’',
            'disgust': 'åŒæ¶',
            'fear': 'ææƒ§',
            'happy': 'å¿«ä¹',
            'sad': 'æ‚²ä¼¤',
            'surprised': 'æƒŠè®¶',
            'neutral': 'å¹³é™'
        }

        # æƒ…ç»ªæ ‡ç­¾åˆ—è¡¨
        self.emotions = list(self.emotion_zh.keys())

        print(f"ğŸ“‚ ç›‘æµ‹æ•°æ®ä¿å­˜åˆ°: {os.path.abspath(save_dir)}")

    def check_camera(self, camera_index=0):
        """
        æ£€æŸ¥æ‘„åƒå¤´è¿æ¥

        Args:
            camera_index: æ‘„åƒå¤´ç´¢å¼•

        Returns:
            tuple: (success, message)
        """
        if not self.camera_available:
            return False, "OpenCVæœªå®‰è£…"

        try:
            print(f"æ£€æŸ¥æ‘„åƒå¤´ {camera_index}...")

            # å°è¯•ç”¨DirectShowåç«¯ï¼ˆWindowsæœ€ç¨³å®šï¼‰
            cap = cv2.VideoCapture(camera_index + cv2.CAP_DSHOW)

            if not cap.isOpened():
                return False, f"æ‘„åƒå¤´ {camera_index} æ— æ³•æ‰“å¼€"

            # æµ‹è¯•è¯»å–ä¸€å¸§
            ret, frame = cap.read()
            cap.release()

            if ret:
                return True, f"æ‘„åƒå¤´ {camera_index} å¯ç”¨"
            else:
                return False, f"æ‘„åƒå¤´ {camera_index} æ— æ³•è¯»å–å›¾åƒ"

        except Exception as e:
            return False, f"æ‘„åƒå¤´æ£€æŸ¥å¤±è´¥: {str(e)}"

    def start_monitoring(self, camera_index=0):
        """
        å¼€å§‹ç›‘æµ‹

        Args:
            camera_index: æ‘„åƒå¤´ç´¢å¼•

        Returns:
            bool: æ˜¯å¦æˆåŠŸå¯åŠ¨
        """
        if not self.camera_available:
            print("âŒ OpenCVæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨æ‘„åƒå¤´")
            return False

        if self.is_monitoring:
            print("âš ï¸  ç›‘æµ‹å·²åœ¨è¿è¡Œä¸­")
            return True

        try:
            # æ£€æŸ¥æ‘„åƒå¤´è¿æ¥
            success, message = self.check_camera(camera_index)
            if not success:
                print(f"âŒ {message}")
                return False

            print(f"ğŸš€ æ­£åœ¨æ‰“å¼€æ‘„åƒå¤´ {camera_index}...")

            # å°è¯•ç”¨DirectShowåç«¯ï¼ˆWindowsï¼‰
            self.camera = cv2.VideoCapture(camera_index + cv2.CAP_DSHOW)

            if not self.camera.isOpened():
                print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_index}")
                return False

            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, 15)

            width = int(self.camera.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = self.camera.get(cv2.CAP_PROP_FPS)

            print(f"âœ… æ‘„åƒå¤´ {camera_index} å·²æ‰“å¼€")
            print(f"ğŸ“Š åˆ†è¾¨ç‡: {width}x{height}, FPS: {fps:.1f}")
            print(f"ğŸ“¸ æŠ“æ‹é—´éš”: {self.capture_interval}ç§’")

            self.is_monitoring = True
            self.is_paused = False

            # å¯åŠ¨ç›‘æµ‹çº¿ç¨‹
            self.monitor_thread = threading.Thread(
                target=self._monitoring_loop,
                args=(camera_index,),
                daemon=True
            )
            self.monitor_thread.start()

            print("ğŸ¬ ç›‘æµ‹çº¿ç¨‹å·²å¯åŠ¨")
            return True

        except Exception as e:
            print(f"âŒ å¯åŠ¨ç›‘æµ‹å¤±è´¥: {e}")
            traceback.print_exc()
            if self.camera:
                self.camera.release()
                self.camera = None
            return False

    def _monitoring_loop(self, camera_index):
        """ç›‘æµ‹å¾ªç¯"""
        print(f"ğŸ” ç›‘æµ‹å¾ªç¯å¼€å§‹ (æ‘„åƒå¤´: {camera_index}, é—´éš”: {self.capture_interval}s)")

        while self.is_monitoring:
            try:
                current_time = time.time()

                # æ£€æŸ¥æš‚åœçŠ¶æ€
                if self.is_paused:
                    time.sleep(0.5)
                    continue

                # è¯»å–æ‘„åƒå¤´å¸§
                ret, frame = self.camera.read()
                if not ret:
                    print("âš ï¸  è¯»å–æ‘„åƒå¤´å¸§å¤±è´¥")
                    time.sleep(1)
                    continue

                # ä¿å­˜å›¾åƒæ–‡ä»¶
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
                image_filename = f"capture_{timestamp}.jpg"
                image_path = os.path.join(self.save_dir, "images", image_filename)

                # ä¿å­˜å›¾åƒ
                try:
                    # è°ƒæ•´å›¾åƒè´¨é‡
                    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 85]
                    success = cv2.imwrite(image_path, frame, encode_param)

                    if success:
                        self.total_captures += 1
                        print(f"ğŸ“¸ ä¿å­˜ç¬¬ {self.total_captures} å¼ å›¾ç‰‡: {image_filename}")

                        # åˆ†æå›¾åƒ
                        result = self._analyze_frame(frame, timestamp, image_filename)

                        if result:
                            self.successful_analyses += 1
                            self._save_result(result, timestamp, image_filename)

                            emotion = result.get('emotion_zh', 'æœªçŸ¥')
                            confidence = result.get('confidence', 0)
                            print(f"âœ… åˆ†æå®Œæˆ: {emotion} ({confidence:.1%})")

                    else:
                        print(f"âŒ ä¿å­˜å›¾ç‰‡å¤±è´¥: {image_path}")

                except Exception as e:
                    print(f"âŒ ä¿å­˜å›¾ç‰‡å¼‚å¸¸: {e}")

                # ç­‰å¾…æŒ‡å®šçš„é—´éš”æ—¶é—´
                time.sleep(self.capture_interval)

            except Exception as e:
                print(f"âŒ ç›‘æµ‹å¾ªç¯é”™è¯¯: {e}")
                traceback.print_exc()
                time.sleep(1)

    def _analyze_frame(self, frame, timestamp, image_filename):
        """
        åˆ†ææ‘„åƒå¤´å¸§

        Args:
            frame: OpenCVå›¾åƒå¸§
            timestamp: æ—¶é—´æˆ³
            image_filename: å›¾åƒæ–‡ä»¶å

        Returns:
            dict: åˆ†æç»“æœæˆ–None
        """
        if self.model is None:
            # æ²¡æœ‰æ¨¡å‹ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            print("âš ï¸  ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æç»“æœ")
            return self._simulate_analysis(frame, timestamp, image_filename)

        try:
            # è½¬æ¢OpenCV BGRåˆ°RGB
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_frame)

            # æ˜¾ç¤ºå›¾åƒä¿¡æ¯
            print(f"ğŸ” åˆ†æå›¾åƒ: {pil_image.size}åƒç´ , æ¨¡å¼: {pil_image.mode}")

            # é¢„å¤„ç†
            img_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)

            # æ¨ç†
            with torch.no_grad():
                outputs = self.model(img_tensor)
                probabilities = torch.softmax(outputs, dim=1)[0]
                predicted_idx = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_idx].item()

            emotion = self.emotions[predicted_idx]

            # æ„é€ æ¦‚ç‡å­—å…¸
            prob_dict = {}
            for i, emotion_name in enumerate(self.emotions):
                prob_dict[emotion_name] = float(probabilities[i])

            result = {
                'timestamp': datetime.now().isoformat(),
                'emotion': emotion,
                'emotion_zh': self.emotion_zh.get(emotion, emotion),
                'confidence': float(confidence),
                'probabilities': prob_dict,
                'image_filename': image_filename,
                'image_path': f"images/{image_filename}"
            }

            return result

        except Exception as e:
            print(f"âŒ åˆ†æå¸§å¤±è´¥: {e}")
            traceback.print_exc()
            return None

    def _simulate_analysis(self, frame, timestamp, image_filename):
        """æ¨¡æ‹Ÿæƒ…ç»ªåˆ†æï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        try:
            import random

            # æ¨¡æ‹Ÿéšæœºæƒ…ç»ª
            emotions = self.emotions
            main_emotion = random.choice(emotions)
            confidence = random.uniform(0.6, 0.9)

            # ç”Ÿæˆæ¨¡æ‹Ÿçš„æ¦‚ç‡åˆ†å¸ƒ
            probabilities = {}
            for emotion in emotions:
                if emotion == main_emotion:
                    probabilities[emotion] = confidence
                else:
                    probabilities[emotion] = (1 - confidence) / (len(emotions) - 1)

            # æ„å»ºç»“æœ
            result = {
                'timestamp': datetime.now().isoformat(),
                'emotion': main_emotion,
                'emotion_zh': self.emotion_zh.get(main_emotion, main_emotion),
                'confidence': float(confidence),
                'probabilities': probabilities,
                'image_filename': image_filename,
                'image_path': f"images/{image_filename}"
            }

            return result

        except Exception as e:
            print(f"âŒ æ¨¡æ‹Ÿåˆ†æå¤±è´¥: {e}")
            return None

    def _save_result(self, result, timestamp, image_filename):
        """
        ä¿å­˜åˆ†æç»“æœ

        Args:
            result: åˆ†æç»“æœå­—å…¸
            timestamp: æ—¶é—´æˆ³
            image_filename: å›¾åƒæ–‡ä»¶å
        """
        try:
            # æ·»åŠ å›¾åƒæ–‡ä»¶ä¿¡æ¯
            result['image_filename'] = image_filename
            result['image_path'] = f"images/{image_filename}"

            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            result_filename = f"result_{timestamp}.json"
            result_path = os.path.join(self.save_dir, "results", result_filename)

            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {result_path}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def pause_monitoring(self):
        """æš‚åœç›‘æµ‹"""
        if self.is_monitoring and not self.is_paused:
            self.is_paused = True
            print("â¸ï¸ ç›‘æµ‹å·²æš‚åœ")
            return True
        return False

    def resume_monitoring(self):
        """ç»§ç»­ç›‘æµ‹"""
        if self.is_monitoring and self.is_paused:
            self.is_paused = False
            print("â–¶ï¸ ç›‘æµ‹å·²ç»§ç»­")
            return True
        return False

    def stop_monitoring(self):
        """åœæ­¢ç›‘æµ‹"""
        if self.is_monitoring:
            print("ğŸ›‘ æ­£åœ¨åœæ­¢ç›‘æµ‹...")
            self.is_monitoring = False
            self.is_paused = False

            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if self.monitor_thread and self.monitor_thread.is_alive():
                self.monitor_thread.join(timeout=2)
                print("âœ… ç›‘æµ‹çº¿ç¨‹å·²åœæ­¢")

            # å…³é—­æ‘„åƒå¤´
            if self.camera:
                self.camera.release()
                self.camera = None
                print("âœ… æ‘„åƒå¤´å·²é‡Šæ”¾")

            print(f"ğŸ“Š ç»Ÿè®¡: å…±æŠ“æ‹ {self.total_captures} å¼ ï¼ŒæˆåŠŸåˆ†æ {self.successful_analyses} å¼ ")
            return True
        return False

    def get_status(self):
        """
        è·å–ç›‘æµ‹çŠ¶æ€

        Returns:
            dict: çŠ¶æ€ä¿¡æ¯
        """
        return {
            'is_monitoring': self.is_monitoring,
            'is_paused': self.is_paused,
            'total_captures': self.total_captures,
            'successful_analyses': self.successful_analyses,
            'capture_interval': self.capture_interval,
            'save_dir': os.path.abspath(self.save_dir),
            'model_loaded': self.model is not None,
            'camera_available': self.camera_available,
            'camera_opened': self.camera is not None and hasattr(self.camera, 'isOpened') and self.camera.isOpened()
        }

    def analyze_history(self, days=None):
        """
        åˆ†æå†å²æ•°æ®

        Args:
            days: åˆ†ææœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰æ•°æ®

        Returns:
            dict: ç»¼åˆåˆ†æç»“æœ
        """
        results_dir = os.path.join(self.save_dir, "results")

        if not os.path.exists(results_dir):
            return {
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°å†å²æ•°æ®ç›®å½•',
                'total_results': 0,
                'results_dir': results_dir
            }

        try:
            # æ”¶é›†æ‰€æœ‰ç»“æœæ–‡ä»¶
            result_files = []
            for filename in os.listdir(results_dir):
                if filename.endswith('.json'):
                    filepath = os.path.join(results_dir, filename)
                    result_files.append(filepath)

            if not result_files:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰åˆ†æç»“æœæ–‡ä»¶',
                    'total_results': 0
                }

            print(f"ğŸ“Š åˆ†æ {len(result_files)} ä¸ªç»“æœæ–‡ä»¶...")

            # è¯»å–ç»“æœ
            all_results = []
            for filepath in result_files:
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        result = json.load(f)
                        all_results.append(result)
                except Exception as e:
                    print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
                    continue

            if not all_results:
                return {
                    'success': False,
                    'error': 'æ— æ³•è¯»å–ç»“æœæ–‡ä»¶',
                    'total_results': 0
                }

            # æŒ‰æ—¶é—´ç­›é€‰
            if days is not None:
                cutoff_time = time.time() - (days * 24 * 3600)
                filtered_results = []
                for result in all_results:
                    try:
                        result_time = datetime.fromisoformat(result['timestamp']).timestamp()
                        if result_time >= cutoff_time:
                            filtered_results.append(result)
                    except:
                        continue
                all_results = filtered_results

            # è¿›è¡Œç»¼åˆåˆ†æ
            analysis = self._comprehensive_analysis(all_results)

            return {
                'success': True,
                'total_results': len(all_results),
                'analysis': analysis,
                'summary': self._generate_summary(all_results)
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'total_results': 0
            }

    def _comprehensive_analysis(self, results):
        """ç»¼åˆåˆ†æ"""
        if not results:
            return {}

        # ç»Ÿè®¡æƒ…ç»ªé¢‘ç‡
        emotion_counts = {}
        emotion_confidences = {}

        for result in results:
            emotion = result.get('emotion', 'unknown')
            confidence = result.get('confidence', 0)

            if emotion not in emotion_counts:
                emotion_counts[emotion] = 0
                emotion_confidences[emotion] = []

            emotion_counts[emotion] += 1
            emotion_confidences[emotion].append(confidence)

        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        avg_confidences = {}
        for emotion, conf_list in emotion_confidences.items():
            if conf_list:
                avg_confidences[emotion] = sum(conf_list) / len(conf_list)
            else:
                avg_confidences[emotion] = 0

        # æ‰¾åˆ°ä¸»è¦æƒ…ç»ª
        if emotion_counts:
            dominant_emotion = max(emotion_counts.items(), key=lambda x: x[1])
        else:
            dominant_emotion = ('unknown', 0)

        return {
            'emotion_distribution': emotion_counts,
            'average_confidences': avg_confidences,
            'dominant_emotion': {
                'emotion': dominant_emotion[0],
                'emotion_zh': self.emotion_zh.get(dominant_emotion[0], dominant_emotion[0]),
                'count': dominant_emotion[1],
                'percentage': (dominant_emotion[1] / len(results)) * 100 if results else 0
            },
            'total_samples': len(results)
        }

    def analyze_history_with_advice(self, days=None):
        """åˆ†æå†å²æ•°æ®å¹¶ç”Ÿæˆå¥åº·å»ºè®®"""
        results_dir = os.path.join(self.save_dir, "results")

        if not os.path.exists(results_dir):
            return {
                'success': False,
                'error': 'æ²¡æœ‰å†å²æ•°æ®ç›®å½•',
                'total_results': 0
            }

        try:
            # æ”¶é›†æ‰€æœ‰ç»“æœæ–‡ä»¶
            result_files = []
            for filename in os.listdir(results_dir):
                if filename.endswith('.json'):
                    filepath = os.path.join(results_dir, filename)
                    result_files.append(filepath)

            if not result_files:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰åˆ†æç»“æœ',
                    'total_results': 0
                }

            print(f"ğŸ“Š åˆ†æ {len(result_files)} ä¸ªç»“æœæ–‡ä»¶...")

            # è¯»å–ç»“æœ
            all_results = []
            for filepath in result_files:
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        result = json.load(f)
                        all_results.append(result)
                except Exception as e:
                    print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
                    continue

            if not all_results:
                return {
                    'success': False,
                    'error': 'æ— æ³•è¯»å–ç»“æœæ–‡ä»¶',
                    'total_results': 0
                }

            # ç»¼åˆåˆ†æ
            analysis = self._comprehensive_analysis(all_results)

            # ç”Ÿæˆå¥åº·å»ºè®®
            health_advice = self._generate_health_advice(analysis)

            # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            summary = self._generate_summary(all_results, analysis, health_advice)

            return {
                'success': True,
                'total_results': len(all_results),
                'analysis': analysis,
                'health_advice': health_advice,
                'summary': summary,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'total_results': 0
            }

    def _generate_health_advice(self, analysis):
        """ç”Ÿæˆå¥åº·å»ºè®®"""
        try:
            # å°è¯•å¯¼å…¥å¥åº·å»ºè®®æ¨¡å—
            try:
                from models.health_advisor import HealthAdvisor, EmotionResult, create_advice_from_probabilities
                advisor_available = True
            except ImportError:
                advisor_available = False
                print("âš ï¸  å¥åº·å»ºè®®æ¨¡å—ä¸å¯ç”¨")

            if not advisor_available:
                # è¿”å›ç®€å•å»ºè®®
                dominant_emotion = analysis.get('dominant_emotion', {})
                emotion = dominant_emotion.get('emotion', 'unknown')
                emotion_zh = self.emotion_zh.get(emotion, emotion)

                return {
                    'description': f'åŸºäºå†å²æ•°æ®åˆ†æï¼Œæ‚¨çš„ä¸»è¦æƒ…ç»ªæ˜¯{emotion_zh}',
                    'recommendations': [
                        'å»ºè®®å®šæœŸè¿›è¡Œæƒ…ç»ªè®°å½•',
                        'æ³¨æ„æƒ…ç»ªå˜åŒ–è¶‹åŠ¿',
                        'ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼'
                    ],
                    'risk_level': 'low' if emotion in ['happy', 'surprised'] else 'medium'
                }

            # ä½¿ç”¨å¥åº·å»ºè®®æ¨¡å—
            emotion_distribution = analysis.get('emotion_distribution', {})
            total_samples = analysis.get('total_samples', 1)

            # è®¡ç®—å¹³å‡æ¦‚ç‡
            probabilities = {}
            for emotion, count in emotion_distribution.items():
                probabilities[emotion] = count / total_samples

            # ç¡®ä¿æ‰€æœ‰æƒ…ç»ªéƒ½æœ‰æ¦‚ç‡
            for emotion in self.emotions:
                if emotion not in probabilities:
                    probabilities[emotion] = 0.0

            # ç”Ÿæˆå»ºè®®
            report = create_advice_from_probabilities(probabilities)

            # æå–å»ºè®®ä¿¡æ¯
            health_advice = {
                'description': report['health_advice']['description'] if 'health_advice' in report else 'æƒ…ç»ªå¥åº·å»ºè®®',
                'immediate_actions': report['health_advice'].get('immediate_actions', []),
                'daily_tips': report['health_advice'].get('daily_tips', []),
                'long_term_suggestions': report['health_advice'].get('long_term_suggestions', []),
                'risk_level': report['risk_assessment'].get('risk_level',
                                                            'unknown') if 'risk_assessment' in report else 'unknown'
            }

            return health_advice

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¥åº·å»ºè®®å¤±è´¥: {e}")
            return {
                'description': 'æƒ…ç»ªåˆ†ææŠ¥å‘Š',
                'recommendations': ['ä¿æŒç§¯æå¿ƒæ€', 'æ³¨æ„æƒ…ç»ªç®¡ç†'],
                'risk_level': 'unknown'
            }

    def _generate_summary(self, all_results, analysis, health_advice):
        """ç”Ÿæˆè¯¦ç»†æ€»ç»“æŠ¥å‘Š"""
        summary = f"ğŸ“Š ç»¼åˆæƒ…ç»ªåˆ†ææŠ¥å‘Š\n"
        summary += f"ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        summary += f"ğŸ“ˆ åˆ†ææ ·æœ¬: {len(all_results)} æ¡æ•°æ®\n\n"

        # æƒ…ç»ªåˆ†å¸ƒ
        summary += "ğŸ­ æƒ…ç»ªåˆ†å¸ƒ:\n"
        emotion_distribution = analysis.get('emotion_distribution', {})
        for emotion, count in sorted(emotion_distribution.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(all_results)) * 100
            emotion_name = self.emotion_zh.get(emotion, emotion)
            summary += f"  {emotion_name}: {count}æ¬¡ ({percentage:.1f}%)\n"

        # ä¸»è¦æƒ…ç»ª
        dominant = analysis.get('dominant_emotion', {})
        if dominant:
            summary += f"\nğŸ‘‘ ä¸»è¦æƒ…ç»ª: {dominant.get('emotion_zh', dominant.get('emotion', 'æœªçŸ¥'))}\n"
            summary += f"   å‡ºç°æ¬¡æ•°: {dominant.get('count', 0)}\n"
            summary += f"   å æ¯”: {dominant.get('percentage', 0):.1f}%\n"

        # ç¨³å®šæ€§åˆ†æ
        stability = analysis.get('stability_score', 0)
        summary += f"\nğŸ“Š æƒ…ç»ªç¨³å®šæ€§: {stability:.1f}%\n"
        if stability > 70:
            summary += "   âœ… æƒ…ç»ªè¾ƒä¸ºç¨³å®š\n"
        elif stability > 40:
            summary += "   âš ï¸  æƒ…ç»ªæœ‰ä¸€å®šæ³¢åŠ¨\n"
        else:
            summary += "   âš ï¸  æƒ…ç»ªæ³¢åŠ¨è¾ƒå¤§\n"

        # å¥åº·å»ºè®®
        summary += f"\nğŸ’¡ å¥åº·å»ºè®®:\n"
        summary += f"   {health_advice.get('description', 'æš‚æ— å»ºè®®')}\n"

        if 'immediate_actions' in health_advice and health_advice['immediate_actions']:
            summary += "\n   ğŸš¨ ç«‹å³è¡ŒåŠ¨:\n"
            for i, action in enumerate(health_advice['immediate_actions'][:3], 1):
                summary += f"     {i}. {action}\n"

        if 'daily_tips' in health_advice and health_advice['daily_tips']:
            summary += "\n   ğŸ“… æ—¥å¸¸è´´å£«:\n"
            for i, tip in enumerate(health_advice['daily_tips'][:3], 1):
                summary += f"     {i}. {tip}\n"

        # é£é™©è¯„ä¼°
        risk_level = health_advice.get('risk_level', 'unknown')
        risk_map = {
            'very_low': 'ğŸŸ¢ é£é™©æä½',
            'low': 'ğŸŸ¢ é£é™©ä½',
            'medium': 'ğŸŸ¡ é£é™©ä¸­ç­‰',
            'high': 'ğŸŸ  é£é™©è¾ƒé«˜',
            'very_high': 'ğŸ”´ é£é™©å¾ˆé«˜'
        }
        summary += f"\nâš ï¸  é£é™©è¯„ä¼°: {risk_map.get(risk_level, 'æœªçŸ¥')}\n"

        return summary

    def get_recent_results(self, limit=10):
        """è·å–æœ€è¿‘çš„ç»“æœ"""
        results_dir = os.path.join(self.save_dir, "results")

        if not os.path.exists(results_dir):
            return []

        try:
            # è·å–æ‰€æœ‰JSONæ–‡ä»¶å¹¶æŒ‰æ—¶é—´æ’åº
            result_files = []
            for filename in os.listdir(results_dir):
                if filename.endswith('.json'):
                    filepath = os.path.join(results_dir, filename)
                    mod_time = os.path.getmtime(filepath)
                    result_files.append((mod_time, filepath))

            # æŒ‰æ—¶é—´æ’åº
            result_files.sort(reverse=True)

            # è¯»å–æœ€è¿‘çš„ç»“æœ
            recent_results = []
            for _, filepath in result_files[:limit]:
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        result = json.load(f)
                        recent_results.append(result)
                except:
                    continue

            return recent_results
        except Exception as e:
            print(f"è·å–æœ€è¿‘ç»“æœå¤±è´¥: {e}")
            return []


# å…¨å±€ç›‘æµ‹å™¨å®ä¾‹
global_monitor = None


def get_monitor(model_path=None, save_dir=None):
    """è·å–å…¨å±€ç›‘æµ‹å™¨å®ä¾‹"""
    global global_monitor

    if global_monitor is None:
        if save_dir is None:
            # ä½¿ç”¨é»˜è®¤ä¿å­˜ç›®å½•
            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            save_dir = os.path.join(base_dir, "data", "monitor_results")

        print(f"ğŸ“ åˆå§‹åŒ–æ‘„åƒå¤´ç›‘æµ‹å™¨...")
        print(f"ğŸ“ ä¿å­˜ç›®å½•: {save_dir}")

        global_monitor = CameraMonitor(model_path=model_path, save_dir=save_dir)
        print("âœ… æ‘„åƒå¤´ç›‘æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")

    return global_monitor


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    print("=" * 60)
    print("æ‘„åƒå¤´ç›‘æµ‹æ¨¡å—æµ‹è¯•")
    print("=" * 60)

    # åˆ›å»ºç›‘æµ‹å™¨
    monitor = get_monitor()

    # æ˜¾ç¤ºçŠ¶æ€
    status = monitor.get_status()
    print(f"çŠ¶æ€: {status}")

    # æµ‹è¯•åŠŸèƒ½
    print("\næµ‹è¯•åŠŸèƒ½:")
    print("1. å¯åŠ¨ç›‘æµ‹ (5ç§’)")
    print("2. æš‚åœ/ç»§ç»­")
    print("3. åœæ­¢ç›‘æµ‹")
    print("4. åˆ†æå†å²æ•°æ®")

    choice = input("\né€‰æ‹©æµ‹è¯• (1-4): ")

    if choice == '1':
        if monitor.start_monitoring():
            print("ç›‘æµ‹å·²å¯åŠ¨ï¼Œç­‰å¾…5ç§’...")
            time.sleep(5)
            monitor.stop_monitoring()
    elif choice == '2':
        print("æš‚åœ/ç»§ç»­åŠŸèƒ½éœ€è¦å…ˆå¯åŠ¨ç›‘æµ‹")
    elif choice == '3':
        monitor.stop_monitoring()
    elif choice == '4':
        analysis = monitor.analyze_history(days=1)
        if analysis['success']:
            print(analysis['summary'])
        else:
            print(f"åˆ†æå¤±è´¥: {analysis['error']}")